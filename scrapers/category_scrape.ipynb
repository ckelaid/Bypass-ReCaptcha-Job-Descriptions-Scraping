{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'driver_config' from 'c:\\\\Users\\\\ckelaid\\\\Documents\\\\Scraping\\\\driver_config.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time \n",
    "import random\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import math\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import pickle\n",
    "import GetSalary\n",
    "import importlib\n",
    "import scrape2_2 as scr2\n",
    "import driver_config as dc\n",
    "import numpy as np\n",
    "import scipy.interpolate as si\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "importlib.reload(scr2)\n",
    "importlib.reload(dc)\n",
    "\n",
    "# Remove DevTools warning\n",
    "#chrome_options.add_experimental_option('excludeSwitches', ['enable-logging'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def human_like_mouse(action:ActionChains, startElem):\n",
    "    # B-spline function\n",
    "    # Curve base:\n",
    "    points = [[0, 0], [0, 2], [2, 3], [4, 0], [6, 3], [8, 2], [8, 0]]\n",
    "    points = np.array(points)\n",
    "\n",
    "    x = points[:,0]\n",
    "    y = points[:,1]\n",
    "\n",
    "\n",
    "    t = range(len(points))\n",
    "    ipl_t = np.linspace(0.0, len(points) - 1, 100)\n",
    "\n",
    "    x_tup = si.splrep(t, x, k=3)\n",
    "    y_tup = si.splrep(t, y, k=3)\n",
    "\n",
    "    x_list = list(x_tup)\n",
    "    xl = x.tolist()\n",
    "    x_list[1] = xl + [0.0, 0.0, 0.0, 0.0]\n",
    "\n",
    "    y_list = list(y_tup)\n",
    "    yl = y.tolist()\n",
    "    y_list[1] = yl + [0.0, 0.0, 0.0, 0.0]\n",
    "\n",
    "    x_i = si.splev(ipl_t, x_list) # x interpolate values\n",
    "    y_i = si.splev(ipl_t, y_list) # y interpolate values\n",
    "\n",
    "    \n",
    "    start_element = startElem\n",
    "\n",
    "    action.move_to_element(start_element)\n",
    "    action.perform()\n",
    "\n",
    "    c = 5\n",
    "    i = 0\n",
    "    for mouse_x, mouse_y in zip(x_i, y_i):\n",
    "        action.move_by_offset(mouse_x,mouse_y)\n",
    "        action.perform()\n",
    "        #print(\"Move mouse to, %s ,%s\" % (mouse_x, mouse_y))   \n",
    "        i += 1    \n",
    "        if i == c:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bypassCaptcha1():\n",
    "\n",
    "    # Switch to captcha iframe\n",
    "    iframe = browser.find_elements(By.TAG_NAME,'iframe')[0]\n",
    "    browser.switch_to.frame(iframe)\n",
    "    iframe = browser.find_elements(By.TAG_NAME,'iframe')[0]\n",
    "    browser.switch_to.frame(iframe)\n",
    "    \n",
    "    # Captcha check button\n",
    "    captcha_check = WebDriverWait(browser, 10).until(EC.element_to_be_clickable((By.XPATH, \"//*[@id='recaptcha-anchor']\")))\n",
    "    browser.implicitly_wait(12)\n",
    "    action =  ActionChains(browser)\n",
    "    # Simulate human like mouse movements\n",
    "    human_like_mouse(action, captcha_check)\n",
    "    captcha_check.click() # Click captcha check\n",
    "\n",
    "\n",
    "    browser.implicitly_wait(8)\n",
    "    action =  ActionChains(browser)\n",
    "    human_like_mouse(action, captcha_check)\n",
    "\n",
    "    browser.switch_to.default_content()\n",
    "\n",
    "    print('\\nSuccessfuly bypassed Captcha 1!\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we get second captcha check\n",
    "#  if browser.find_elements(By.TAG_NAME,'iframe')[0].text.startswith('Request unsuccessful.'):\n",
    "\n",
    "def bypassCaptcha2():\n",
    "\n",
    "    t = random.randint(8,10)\n",
    "    browser.implicitly_wait(t)\n",
    "\n",
    "    iframe2 = browser.find_elements(By.TAG_NAME,\"iframe\")[0]\n",
    "    browser.switch_to.frame(iframe2)\n",
    "    iframe3 = browser.find_elements(By.XPATH,\"//iframe[@title='recaptcha challenge expires in two minutes']\")[0]\n",
    "    browser.switch_to.frame(iframe3)\n",
    "    # Find nearest element to #shadow-root (closed)\n",
    "    elem = browser.find_element(By.XPATH, '//div[@class=\"button-holder help-button-holder\"]')\n",
    "    browser.implicitly_wait(10)\n",
    "    elem.click() # click on it\n",
    "    browser.switch_to.default_content()\n",
    "\n",
    "    print('\\nSuccessfuly bypassed Captcha 2!\\n')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Programmer_Analyst', '159')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = ['IT_Support_and_Training', 'Programmer_Analyst', 'IT_Manager_Director', 'Business_and_Financial_Services']\n",
    "cat_nums = ['161', '159', '163', '188']\n",
    "\n",
    "category = categories[1] \n",
    "cat_num = cat_nums[1]\n",
    "\n",
    "category, cat_num"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape page links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.higheredjobs.com/admin/search.cfm?JobCat=159&StartRow=1&SortBy=4&NumJobs=100&filterby=&CatType=\n",
      "There are 11 pages\n"
     ]
    }
   ],
   "source": [
    "#base = 'https://www.higheredjobs.com/search/advanced_action.cfm?Remote=&Keyword='\n",
    "page_num = 1\n",
    "url = 'https://www.higheredjobs.com/admin/search.cfm?JobCat='+cat_num+'&StartRow='+str(page_num)+'&SortBy=4&NumJobs=100&filterby=&CatType='\n",
    "# page = '&PosType=&InstType=&JobCat=&Region=0&SubRegions=&Metros=&OnlyTitle=0&JobCatType=&StartRow='+str(page_num)+'&SortBy=1&NumJobs=100&CatType='\n",
    "# x = 'workday'\n",
    "# url = base+x+page\n",
    "\n",
    "print(url)\n",
    "\n",
    "browser = dc.initialize_driver()\n",
    "t = random.randint(8,10)\n",
    "WebDriverWait(browser, t)\n",
    "browser.get(url)\n",
    "try:\n",
    "    # wait for page to load\n",
    "    WebDriverWait(browser, 20).until(\n",
    "        EC.presence_of_element_located((By.CLASS_NAME, 'text-nowrap'))\n",
    "    )\n",
    "    max_jobs = browser.find_element(By.CLASS_NAME, 'text-nowrap').text.split(' ')[5]\n",
    "    max_jobs = int(\"\".join(max_jobs.split(','))) # remove ',' so that we can convert to int \n",
    "    num_pages = math.ceil(max_jobs/100) # /100 because we iterate 100 links per page\n",
    "    browser.quit()\n",
    "\n",
    "    page_links = []\n",
    "    page_links.append(url) #1st page\n",
    "\n",
    "    # for page 2 until the last page\n",
    "    for p in range(1, num_pages): #=> we want to +100 for as many pages as we iterate through to the page link, starting at the 2nd page\n",
    "        page_num = page_num + 100\n",
    "        url = 'https://www.higheredjobs.com/admin/search.cfm?JobCat='+cat_num+'&StartRow='+str(page_num)+'&SortBy=4&NumJobs=100&filterby=&CatType='\n",
    "        # page = '&PosType=&InstType=&JobCat=&Region=0&SubRegions=&Metros=&OnlyTitle=0&JobCatType=&StartRow='+str(page_num)+'&SortBy=1&NumJobs=100&CatType='\n",
    "        # url = base+x+page\n",
    "        page_links.append(url)\n",
    "\n",
    "    print(\"There are {} pages\".format(len(page_links)))\n",
    "    # Save page links\n",
    "    with open('Page_Links_'+category+'.pkl', 'wb') as f:\n",
    "                    pickle.dump(page_links, f)\n",
    "\n",
    "except Exception: \n",
    "    # Check that exception is b/c of Captcha\n",
    "    if browser.find_elements(By.TAG_NAME,'iframe')[0].text.startswith('Request unsuccessful.'):\n",
    "        ppp = 0\n",
    "        while ppp < 1:\n",
    "            try:\n",
    "                WebDriverWait(browser, 60)\n",
    "                iframe = browser.find_elements(By.TAG_NAME,'iframe')[0]\n",
    "                WebDriverWait(browser, 10)\n",
    "                browser.switch_to.frame(iframe)\n",
    "                WebDriverWait(browser, 10)\n",
    "                browser.find_element(By.XPATH, \"//*[@id='recaptcha-anchor']\").click()\n",
    "                time.sleep(20) # manually solve image challenge => that worked\n",
    "                ppp = 1\n",
    "            except Exception:\n",
    "                ppp = 0\n",
    "        max_jobs = browser.find_element(By.CLASS_NAME, 'text-nowrap').text.split(' ')[5]\n",
    "        max_jobs = int(\"\".join(max_jobs.split(','))) # remove ',' so that we can convert to int \n",
    "        num_pages = math.ceil(max_jobs/100) # /100 because we iterate 100 links per page\n",
    "        browser.quit()\n",
    "\n",
    "        page_links = []\n",
    "        page_links.append(url) #1st page\n",
    "\n",
    "        # for page 2 until the last page\n",
    "        for p in range(1, num_pages): #=> we want to +100 for as many pages as we iterate through to the page link, starting at the 2nd page\n",
    "            page_num = page_num + 100\n",
    "            url = 'https://www.higheredjobs.com/admin/search.cfm?JobCat='+cat_num+'&StartRow='+str(page_num)+'&SortBy=4&NumJobs=100&filterby=&CatType='\n",
    "            # page = '&PosType=&InstType=&JobCat=&Region=0&SubRegions=&Metros=&OnlyTitle=0&JobCatType=&StartRow='+str(page_num)+'&SortBy=1&NumJobs=100&CatType='\n",
    "            # url = base+x+page\n",
    "            page_links.append(url)\n",
    "\n",
    "        print(\"There are {} pages\".format(len(page_links)))\n",
    "        # Save page links\n",
    "        with open('Page_Links_'+category+'.pkl', 'wb') as f:\n",
    "                    pickle.dump(page_links, f)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Page_Links_Programmer_Analyst.pkl', 11)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Page_Links_'+category+'.pkl',len(page_links)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape job links "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('Page_Links_'+category+'.pkl', 'rb') as f:\n",
    "    page_links = pickle.load(f)\n",
    "\n",
    "len(page_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_links = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job link\n",
      "\n",
      "Pausing 20 minutes, buster API overused!\n",
      "Trying again\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job link\n",
      "\n",
      "Trying again\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job link\n",
      "\n",
      "Trying again\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job link\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job link\n",
      "\n",
      "Pausing 20 minutes, buster API overused!\n",
      "Trying again\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job link\n",
      "\n",
      "Trying again\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job link\n",
      "\n",
      "Trying again\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job link\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job link\n",
      "\n",
      "Pausing 20 minutes, buster API overused!\n",
      "Trying again\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job link\n",
      "\n",
      "Trying again\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job link\n",
      "\n",
      "Trying again\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job link\n",
      "\n",
      "Pausing for another 20\n",
      "Trying again\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job link\n",
      "\n",
      "Pausing for an hour!\n",
      "Trying again\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job link\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job link\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job link\n",
      "\n",
      "Pausing 20 minutes, buster API overused!\n",
      "Trying again\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job link\n",
      "\n",
      "Trying again\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job link\n",
      "\n",
      "Trying again\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job link\n",
      "\n",
      "Pausing for another 20\n",
      "Trying again\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job link\n",
      "\n",
      "Pausing for an hour!\n",
      "Trying again\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job link\n",
      "\n",
      "Pausing for an hour!\n",
      "Trying again\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job link\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job link\n",
      "\n",
      "Pausing 20 minutes, buster API overused!\n",
      "Trying again\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job link\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for link in page_links:\n",
    "    t = random.randint(8,10)\n",
    "    time.sleep(t)\n",
    "    browser = dc.initialize_driver()\n",
    "    browser.get(link)\n",
    "    try:\n",
    "        # wait for page to load\n",
    "        WebDriverWait(browser, 20).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, 'col-sm-7'))\n",
    "        )\n",
    "        # get job links\n",
    "        div = browser.find_elements(By.CLASS_NAME, 'col-sm-7')\n",
    "        for d in div:\n",
    "            job_links.append(d.find_element(By.CSS_SELECTOR, 'a').get_attribute('href'))\n",
    "        browser.quit()\n",
    "        with open('Job_links_'+category+'.pkl', 'wb') as f:\n",
    "            pickle.dump(job_links, f)\n",
    "    except Exception:\n",
    "        # print('bypassing Captcha')\n",
    "        # WebDriverWait(browser, 10).until(\n",
    "        #     EC.presence_of_all_elements_located((By.TAG_NAME,'iframe'))\n",
    "        # )\n",
    "        # Check that exception is b/c of Captcha\n",
    "        if browser.find_elements(By.TAG_NAME,'iframe')[0].text.startswith('Request unsuccessful.'):\n",
    "\n",
    "            #bypassFullCaptcha()\n",
    "            bypassCaptcha1()\n",
    "            \n",
    "            # Check if we get second captcha check\n",
    "            if browser.find_elements(By.TAG_NAME,'iframe')[0].text.startswith('Request unsuccessful.'):\n",
    "                \n",
    "                bypassCaptcha2()\n",
    "                time.sleep(10)\n",
    "\n",
    "        try:\n",
    "            print('Looking for job link\\n')\n",
    "                \n",
    "            # Successfully moved out of Captcha\n",
    "\n",
    "            # wait for page to load\n",
    "            WebDriverWait(browser, 20).until(\n",
    "                    EC.presence_of_element_located((By.CLASS_NAME, 'col-sm-7'))\n",
    "            ) \n",
    "            # get job links\n",
    "            div = browser.find_elements(By.CLASS_NAME, 'col-sm-7')\n",
    "            for d in div:\n",
    "                job_links.append(d.find_element(By.CSS_SELECTOR, 'a').get_attribute('href'))\n",
    "            browser.quit()\n",
    "            with open('Job_links_'+category+'.pkl', 'wb') as f:\n",
    "                pickle.dump(job_links, f)\n",
    "        \n",
    "        except Exception:\n",
    "            # API limit exceeded and need to wait, pause 20 minutes and try again\n",
    "            browser.quit()\n",
    "            print('Pausing 20 minutes, buster API overused!')\n",
    "            time.sleep(1200) # wait 20 minutes :( looooooong\n",
    "\n",
    "            pp = 0\n",
    "            aa = 0\n",
    "            while pp < 1:\n",
    "                try:\n",
    "                    browser = dc.initialize_driver()\n",
    "                    browser.get(link)\n",
    "\n",
    "                    #browser.switch_to.default_content()\n",
    "                    \n",
    "                    if browser.find_elements(By.TAG_NAME,'iframe')[0].text.startswith('Request unsuccessful.'):\n",
    "                        print('Trying again')\n",
    "\n",
    "                        time.sleep(10)\n",
    "\n",
    "                        bypassCaptcha1()\n",
    "\n",
    "                        # Check if we get second captcha check\n",
    "                        if browser.find_elements(By.TAG_NAME,'iframe')[0].text.startswith('Request unsuccessful.'):\n",
    "\n",
    "                            bypassCaptcha2()\n",
    "                            time.sleep(10)\n",
    "\n",
    "                        print('Looking for job link\\n')\n",
    "                            \n",
    "                        # Successfully moved out of Captcha\n",
    "\n",
    "                        # wait for page to load\n",
    "                        WebDriverWait(browser, 20).until(\n",
    "                                EC.presence_of_element_located((By.CLASS_NAME, 'col-sm-7'))\n",
    "                        ) \n",
    "                        # get job links\n",
    "                        div = browser.find_elements(By.CLASS_NAME, 'col-sm-7')\n",
    "                        for d in div:\n",
    "                            job_links.append(d.find_element(By.CSS_SELECTOR, 'a').get_attribute('href'))\n",
    "                        browser.quit()\n",
    "                        with open('Job_links_'+category+'.pkl', 'wb') as f:\n",
    "                            pickle.dump(job_links, f)\n",
    "                        pp = 1\n",
    "                    \n",
    "                except Exception:\n",
    "                    time.sleep(60)\n",
    "                    browser.implicitly_wait(7)\n",
    "                    browser.quit()\n",
    "                    pp = 0\n",
    "                    aa = aa+1\n",
    "                    if aa == 5:\n",
    "                        print('Pausing for 30')\n",
    "                        time.sleep(1800) # 30 minutes\n",
    "                    \n",
    "                    if aa > 5:\n",
    "                        print('Pausing for 5 hours!')\n",
    "                        time.sleep(18000)\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "846"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(job_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 837 jobs to scrape\n"
     ]
    }
   ],
   "source": [
    "# Cleaning job_links\n",
    "\n",
    "# Deleting wrong entries\n",
    "del_ix = []\n",
    "for i in range(len(job_links)):\n",
    "    if job_links[i] == 'javascript:;':\n",
    "        del_ix.append(i) \n",
    "\n",
    "# Also check that no job_links == category_page url\n",
    "for j in range(len(job_links)):\n",
    "    if job_links[j] == 'https://www.higheredjobs.com/admin/search.cfm?JobCat='+cat_num+'&SortBy=4&StartRow=1':\n",
    "        del_ix.append(j)\n",
    "\n",
    "if len(del_ix) > 0:\n",
    "    # delete 'javascript:;' entries & incorrect url entries\n",
    "    del job_links[del_ix[0]]\n",
    "\n",
    "    drop = 1\n",
    "    for i in range(1, len(del_ix)):\n",
    "        del job_links[del_ix[i]-drop]\n",
    "        drop = drop + 1\n",
    "\n",
    "print(\"There are {} jobs to scrape\".format(len(job_links)))\n",
    "\n",
    "# Save job links\n",
    "with open('Job_links_'+category+'.pkl', 'wb') as f:\n",
    "            pickle.dump(job_links, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "837"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(job_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('JOB_links_IT_Support_and_Training.pkl', 837)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('Job_links_'+category+'.pkl', 'rb') as f:\n",
    "    job_links = pickle.load(f)\n",
    "\n",
    "'JOB_links_'+category+'.pkl',len(job_links)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape job attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Job_Attrs_IT_Manager_Director.pkl', 26)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with open('Job_Attrs.pkl', 'rb') as f:\n",
    "#     job_attrs = pickle.load(f)\n",
    "\n",
    "# len(job_attrs)\n",
    "\n",
    "\n",
    "\n",
    "# with open('Job_Attrs_'+category+'.pkl', 'rb') as f:\n",
    "#     job_attrs = pickle.load(f)\n",
    "\n",
    "\n",
    "# 'Job_Attrs_'+category+'.pkl', len(job_attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131, 960, 'Programmer_Analyst')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(job_attrs), len(job_links[133:]), category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#job_attrs = []\n",
    "#job_dict = {}\n",
    "not_scraped = 3\n",
    "scraped = 133\n",
    "smile = 133"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for job info 134\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Job 134 has been deleted\n",
      "Looking for job info 135\n",
      "\n",
      "\n",
      "Not scraped is 4\n",
      "\n",
      "Job 135 has been deleted\n",
      "Looking for job info 136\n",
      "\n",
      "\n",
      "Not scraped is 5\n",
      "\n",
      "Job 136 has been deleted\n",
      "Looking for job info 138\n",
      "\n",
      "\n",
      "Not scraped is 6\n",
      "\n",
      "Job 138 has been deleted\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 139\n",
      "\n",
      "\n",
      "Not scraped is 7\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 140\n",
      "\n",
      "\n",
      "Not scraped is 7\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 141\n",
      "\n",
      "\n",
      "Not scraped is 7\n",
      "Pausing 20 minutes, buster API overused!\n",
      "Trying again on job  141\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 141\n",
      "\n",
      "\n",
      "Not scraped is 7\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 142\n",
      "\n",
      "\n",
      "Not scraped is 7\n",
      "\n",
      "Job 142 has been deleted\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 143\n",
      "\n",
      "\n",
      "Not scraped is 8\n",
      "Pausing 20 minutes, buster API overused!\n",
      "Trying again on job  143\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 143\n",
      "\n",
      "\n",
      "Not scraped is 8\n",
      "\n",
      "aa is \n",
      " 1\n",
      "Trying again on job  143\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 143\n",
      "\n",
      "\n",
      "Not scraped is 8\n",
      "\n",
      "Job 143 has been deleted\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 144\n",
      "\n",
      "\n",
      "Not scraped is 9\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 145\n",
      "\n",
      "\n",
      "Not scraped is 9\n",
      "Pausing 20 minutes, buster API overused!\n",
      "Trying again on job  145\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 145\n",
      "\n",
      "\n",
      "Not scraped is 9\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 146\n",
      "\n",
      "\n",
      "Not scraped is 9\n",
      "Pausing 20 minutes, buster API overused!\n",
      "Trying again on job  146\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 146\n",
      "\n",
      "\n",
      "Not scraped is 9\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 147\n",
      "\n",
      "\n",
      "Not scraped is 9\n",
      "Pausing 20 minutes, buster API overused!\n",
      "Trying again on job  147\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 147\n",
      "\n",
      "\n",
      "Not scraped is 9\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 148\n",
      "\n",
      "\n",
      "Not scraped is 9\n",
      "Pausing 20 minutes, buster API overused!\n",
      "Trying again on job  148\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 148\n",
      "\n",
      "\n",
      "Not scraped is 9\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 149\n",
      "\n",
      "\n",
      "Not scraped is 9\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 150\n",
      "\n",
      "\n",
      "Not scraped is 9\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 151\n",
      "\n",
      "\n",
      "Not scraped is 9\n",
      "Pausing 20 minutes, buster API overused!\n",
      "Trying again on job  151\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 151\n",
      "\n",
      "\n",
      "Not scraped is 9\n",
      "\n",
      "aa is \n",
      " 1\n",
      "Trying again on job  151\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 151\n",
      "\n",
      "\n",
      "Not scraped is 9\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 152\n",
      "\n",
      "\n",
      "Not scraped is 9\n",
      "Pausing 20 minutes, buster API overused!\n",
      "Trying again on job  152\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 152\n",
      "\n",
      "\n",
      "Not scraped is 9\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 153\n",
      "\n",
      "\n",
      "Not scraped is 9\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 154\n",
      "\n",
      "\n",
      "Not scraped is 9\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 155\n",
      "\n",
      "\n",
      "Not scraped is 9\n",
      "Pausing 20 minutes, buster API overused!\n",
      "Trying again on job  155\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 155\n",
      "\n",
      "\n",
      "Not scraped is 9\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 156\n",
      "\n",
      "\n",
      "Not scraped is 9\n",
      "Pausing 20 minutes, buster API overused!\n",
      "Trying again on job  156\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 156\n",
      "\n",
      "\n",
      "Not scraped is 9\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 157\n",
      "\n",
      "\n",
      "Not scraped is 9\n",
      "Pausing 20 minutes, buster API overused!\n",
      "Trying again on job  157\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 157\n",
      "\n",
      "\n",
      "Not scraped is 9\n",
      "\n",
      "aa is \n",
      " 1\n",
      "Trying again on job  157\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 157\n",
      "\n",
      "\n",
      "Not scraped is 9\n",
      "\n",
      "aa is \n",
      " 2\n",
      "Trying again on job  157\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 157\n",
      "\n",
      "\n",
      "Not scraped is 9\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 158\n",
      "\n",
      "\n",
      "Not scraped is 9\n",
      "Pausing 20 minutes, buster API overused!\n",
      "Trying again on job  158\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 158\n",
      "\n",
      "\n",
      "Not scraped is 9\n",
      "\n",
      "aa is \n",
      " 1\n",
      "Trying again on job  158\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 158\n",
      "\n",
      "\n",
      "Not scraped is 9\n",
      "\n",
      "aa is \n",
      " 2\n",
      "Trying again on job  158\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 158\n",
      "\n",
      "\n",
      "Not scraped is 9\n",
      "\n",
      "aa is \n",
      " 3\n",
      "Trying again on job  158\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 158\n",
      "\n",
      "\n",
      "Not scraped is 9\n",
      "\n",
      "aa is \n",
      " 4\n",
      "Trying again on job  158\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 158\n",
      "\n",
      "\n",
      "Not scraped is 9\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 159\n",
      "\n",
      "\n",
      "Not scraped is 9\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 160\n",
      "\n",
      "\n",
      "Not scraped is 9\n",
      "Pausing 20 minutes, buster API overused!\n",
      "Trying again on job  160\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 160\n",
      "\n",
      "\n",
      "Not scraped is 9\n",
      "\n",
      "aa is \n",
      " 1\n",
      "Trying again on job  160\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 160\n",
      "\n",
      "\n",
      "Not scraped is 9\n",
      "\n",
      "aa is \n",
      " 2\n",
      "Trying again on job  160\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 160\n",
      "\n",
      "\n",
      "Not scraped is 9\n",
      "\n",
      "aa is \n",
      " 3\n",
      "Trying again on job  160\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 160\n",
      "\n",
      "\n",
      "Not scraped is 9\n",
      "\n",
      "aa is \n",
      " 4\n",
      "Trying again on job  160\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 160\n",
      "\n",
      "\n",
      "Not scraped is 9\n",
      "\n",
      "aa is \n",
      " 5\n",
      "Pausing for 30 minutes\n",
      "Trying again on job  160\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 160\n",
      "\n",
      "\n",
      "Not scraped is 9\n",
      "\n",
      "aa is \n",
      " 6\n",
      "Pausing for five hours!\n",
      "Trying again on job  160\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 160\n",
      "\n",
      "\n",
      "Not scraped is 9\n",
      "\n",
      "aa is \n",
      " 7\n",
      "Pausing for five hours!\n",
      "Trying again on job  160\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 160\n",
      "\n",
      "\n",
      "Not scraped is 9\n",
      "\n",
      "aa is \n",
      " 8\n",
      "Pausing for five hours!\n",
      "Trying again on job  160\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 160\n",
      "\n",
      "\n",
      "Not scraped is 9\n",
      "\n",
      "aa is \n",
      " 9\n",
      "Pausing for five hours!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3324\\3971382243.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m         WebDriverWait(browser, 20).until(\n\u001b[1;32m---> 10\u001b[1;33m             \u001b[0mEC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpresence_of_element_located\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCLASS_NAME\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'row'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         )\n",
      "\u001b[1;32mc:\\Users\\ckelaid\\Anaconda3\\envs\\scrape\\lib\\site-packages\\selenium\\webdriver\\support\\wait.py\u001b[0m in \u001b[0;36muntil\u001b[1;34m(self, method, message)\u001b[0m\n\u001b[0;32m     94\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTimeoutException\u001b[0m: Message: \nStacktrace:\nBacktrace:\n\t(No symbol) [0x00B86643]\n\t(No symbol) [0x00B1BE21]\n\t(No symbol) [0x00A1DA9D]\n\t(No symbol) [0x00A51342]\n\t(No symbol) [0x00A5147B]\n\t(No symbol) [0x00A88DC2]\n\t(No symbol) [0x00A6FDC4]\n\t(No symbol) [0x00A86B09]\n\t(No symbol) [0x00A6FB76]\n\t(No symbol) [0x00A449C1]\n\t(No symbol) [0x00A45E5D]\n\tGetHandleVerifier [0x00DFA142+2497106]\n\tGetHandleVerifier [0x00E285D3+2686691]\n\tGetHandleVerifier [0x00E2BB9C+2700460]\n\tGetHandleVerifier [0x00C33B10+635936]\n\t(No symbol) [0x00B24A1F]\n\t(No symbol) [0x00B2A418]\n\t(No symbol) [0x00B2A505]\n\t(No symbol) [0x00B3508B]\n\tBaseThreadInitThunk [0x763900F9+25]\n\tRtlGetAppContainerNamedObjectPath [0x77237BBE+286]\n\tRtlGetAppContainerNamedObjectPath [0x77237B8E+238]\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3324\\3971382243.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     93\u001b[0m             WebDriverWait(browser, 20).until(\n\u001b[1;32m---> 94\u001b[1;33m                 \u001b[0mEC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpresence_of_element_located\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCLASS_NAME\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'row'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m             )\n",
      "\u001b[1;32mc:\\Users\\ckelaid\\Anaconda3\\envs\\scrape\\lib\\site-packages\\selenium\\webdriver\\support\\wait.py\u001b[0m in \u001b[0;36muntil\u001b[1;34m(self, method, message)\u001b[0m\n\u001b[0;32m     94\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTimeoutException\u001b[0m: Message: \nStacktrace:\nBacktrace:\n\t(No symbol) [0x00B86643]\n\t(No symbol) [0x00B1BE21]\n\t(No symbol) [0x00A1DA9D]\n\t(No symbol) [0x00A51342]\n\t(No symbol) [0x00A5147B]\n\t(No symbol) [0x00A88DC2]\n\t(No symbol) [0x00A6FDC4]\n\t(No symbol) [0x00A86B09]\n\t(No symbol) [0x00A6FB76]\n\t(No symbol) [0x00A449C1]\n\t(No symbol) [0x00A45E5D]\n\tGetHandleVerifier [0x00DFA142+2497106]\n\tGetHandleVerifier [0x00E285D3+2686691]\n\tGetHandleVerifier [0x00E2BB9C+2700460]\n\tGetHandleVerifier [0x00C33B10+635936]\n\t(No symbol) [0x00B24A1F]\n\t(No symbol) [0x00B2A418]\n\t(No symbol) [0x00B2A505]\n\t(No symbol) [0x00B3508B]\n\tBaseThreadInitThunk [0x763900F9+25]\n\tRtlGetAppContainerNamedObjectPath [0x77237BBE+286]\n\tRtlGetAppContainerNamedObjectPath [0x77237B8E+238]\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ckelaid\\Anaconda3\\envs\\scrape\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    174\u001b[0m             conn = connection.create_connection(\n\u001b[1;32m--> 175\u001b[1;33m                 \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dns_host\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m             )\n",
      "\u001b[1;32mc:\\Users\\ckelaid\\Anaconda3\\envs\\scrape\\lib\\site-packages\\urllib3\\util\\connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ckelaid\\Anaconda3\\envs\\scrape\\lib\\site-packages\\urllib3\\util\\connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     84\u001b[0m                 \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m             \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConnectionRefusedError\u001b[0m: [WinError 10061] No connection could be made because the target machine actively refused it",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ckelaid\\Anaconda3\\envs\\scrape\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    709\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 710\u001b[1;33m                 \u001b[0mchunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    711\u001b[0m             )\n",
      "\u001b[1;32mc:\\Users\\ckelaid\\Anaconda3\\envs\\scrape\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    397\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 398\u001b[1;33m                 \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ckelaid\\Anaconda3\\envs\\scrape\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, body, headers)\u001b[0m\n\u001b[0;32m    238\u001b[0m             \u001b[0mheaders\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"User-Agent\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_default_user_agent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHTTPConnection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ckelaid\\Anaconda3\\envs\\scrape\\lib\\http\\client.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1280\u001b[0m         \u001b[1;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1281\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1282\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ckelaid\\Anaconda3\\envs\\scrape\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1326\u001b[0m             \u001b[0mbody\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'body'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ckelaid\\Anaconda3\\envs\\scrape\\lib\\http\\client.py\u001b[0m in \u001b[0;36mendheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1275\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1276\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ckelaid\\Anaconda3\\envs\\scrape\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1035\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1036\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1037\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ckelaid\\Anaconda3\\envs\\scrape\\lib\\http\\client.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    975\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 976\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    977\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ckelaid\\Anaconda3\\envs\\scrape\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m         \u001b[0mconn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_prepare_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ckelaid\\Anaconda3\\envs\\scrape\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    186\u001b[0m             raise NewConnectionError(\n\u001b[1;32m--> 187\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Failed to establish a new connection: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m             )\n",
      "\u001b[1;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x000001D9D09CE488>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3324\\3971382243.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    157\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[0mdel_div\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'We require users to verify the reCaptcha below to view deleted positions'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ckelaid\\Anaconda3\\envs\\scrape\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001b[0m in \u001b[0;36mtext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[1;34m\"\"\"The text of the element.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_execute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGET_ELEMENT_TEXT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ckelaid\\Anaconda3\\envs\\scrape\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001b[0m in \u001b[0;36m_execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    409\u001b[0m         \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"id\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 410\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ckelaid\\Anaconda3\\envs\\scrape\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 442\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    443\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ckelaid\\Anaconda3\\envs\\scrape\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"{self._url}{path}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 294\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    295\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ckelaid\\Anaconda3\\envs\\scrape\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py\u001b[0m in \u001b[0;36m_request\u001b[1;34m(self, method, url, body)\u001b[0m\n\u001b[0;32m    315\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeep_alive\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m             \u001b[0mstatuscode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ckelaid\\Anaconda3\\envs\\scrape\\lib\\site-packages\\urllib3\\request.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[0;32m     74\u001b[0m             return self.request_encode_url(\n\u001b[1;32m---> 75\u001b[1;33m                 \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfields\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0murlopen_kw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m             )\n",
      "\u001b[1;32mc:\\Users\\ckelaid\\Anaconda3\\envs\\scrape\\lib\\site-packages\\urllib3\\request.py\u001b[0m in \u001b[0;36mrequest_encode_url\u001b[1;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ckelaid\\Anaconda3\\envs\\scrape\\lib\\site-packages\\urllib3\\poolmanager.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[0;32m    375\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 376\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest_uri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    377\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ckelaid\\Anaconda3\\envs\\scrape\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    827\u001b[0m                 \u001b[0mbody_pos\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody_pos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m                 \u001b[1;33m**\u001b[0m\u001b[0mresponse_kw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m             )\n",
      "\u001b[1;32mc:\\Users\\ckelaid\\Anaconda3\\envs\\scrape\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    827\u001b[0m                 \u001b[0mbody_pos\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody_pos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m                 \u001b[1;33m**\u001b[0m\u001b[0mresponse_kw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m             )\n",
      "\u001b[1;32mc:\\Users\\ckelaid\\Anaconda3\\envs\\scrape\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    827\u001b[0m                 \u001b[0mbody_pos\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody_pos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m                 \u001b[1;33m**\u001b[0m\u001b[0mresponse_kw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m             )\n",
      "\u001b[1;32mc:\\Users\\ckelaid\\Anaconda3\\envs\\scrape\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    787\u001b[0m             retries = retries.increment(\n\u001b[1;32m--> 788\u001b[1;33m                 \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    789\u001b[0m             )\n",
      "\u001b[1;32mc:\\Users\\ckelaid\\Anaconda3\\envs\\scrape\\lib\\site-packages\\urllib3\\util\\retry.py\u001b[0m in \u001b[0;36mincrement\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    591\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 592\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    593\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='localhost', port=59676): Max retries exceeded with url: /session/83babc504599544fbaaca41b8748c8ce/element/a8d6d914-8dc5-438c-81e2-de447214b191/text (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001D9D09CE488>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3324\\3971382243.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    212\u001b[0m                             WebDriverWait(browser, 20).until(\n\u001b[1;32m--> 213\u001b[1;33m                                 \u001b[0mEC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpresence_of_element_located\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCLASS_NAME\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'row'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m                             )\n",
      "\u001b[1;32mc:\\Users\\ckelaid\\Anaconda3\\envs\\scrape\\lib\\site-packages\\selenium\\webdriver\\support\\wait.py\u001b[0m in \u001b[0;36muntil\u001b[1;34m(self, method, message)\u001b[0m\n\u001b[0;32m     94\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTimeoutException\u001b[0m: Message: \nStacktrace:\nBacktrace:\n\t(No symbol) [0x00B86643]\n\t(No symbol) [0x00B1BE21]\n\t(No symbol) [0x00A1DA9D]\n\t(No symbol) [0x00A51342]\n\t(No symbol) [0x00A5147B]\n\t(No symbol) [0x00A88DC2]\n\t(No symbol) [0x00A6FDC4]\n\t(No symbol) [0x00A86B09]\n\t(No symbol) [0x00A6FB76]\n\t(No symbol) [0x00A449C1]\n\t(No symbol) [0x00A45E5D]\n\tGetHandleVerifier [0x00DFA142+2497106]\n\tGetHandleVerifier [0x00E285D3+2686691]\n\tGetHandleVerifier [0x00E2BB9C+2700460]\n\tGetHandleVerifier [0x00C33B10+635936]\n\t(No symbol) [0x00B24A1F]\n\t(No symbol) [0x00B2A418]\n\t(No symbol) [0x00B2A505]\n\t(No symbol) [0x00B3508B]\n\tBaseThreadInitThunk [0x763900F9+25]\n\tRtlGetAppContainerNamedObjectPath [0x77237BBE+286]\n\tRtlGetAppContainerNamedObjectPath [0x77237B8E+238]\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ckelaid\\Anaconda3\\envs\\scrape\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    174\u001b[0m             conn = connection.create_connection(\n\u001b[1;32m--> 175\u001b[1;33m                 \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dns_host\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m             )\n",
      "\u001b[1;32mc:\\Users\\ckelaid\\Anaconda3\\envs\\scrape\\lib\\site-packages\\urllib3\\util\\connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ckelaid\\Anaconda3\\envs\\scrape\\lib\\site-packages\\urllib3\\util\\connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     84\u001b[0m                 \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m             \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConnectionRefusedError\u001b[0m: [WinError 10061] No connection could be made because the target machine actively refused it",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ckelaid\\Anaconda3\\envs\\scrape\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    709\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 710\u001b[1;33m                 \u001b[0mchunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    711\u001b[0m             )\n",
      "\u001b[1;32mc:\\Users\\ckelaid\\Anaconda3\\envs\\scrape\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    397\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 398\u001b[1;33m                 \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ckelaid\\Anaconda3\\envs\\scrape\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, body, headers)\u001b[0m\n\u001b[0;32m    238\u001b[0m             \u001b[0mheaders\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"User-Agent\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_default_user_agent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHTTPConnection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ckelaid\\Anaconda3\\envs\\scrape\\lib\\http\\client.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1280\u001b[0m         \u001b[1;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1281\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1282\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ckelaid\\Anaconda3\\envs\\scrape\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1326\u001b[0m             \u001b[0mbody\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'body'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ckelaid\\Anaconda3\\envs\\scrape\\lib\\http\\client.py\u001b[0m in \u001b[0;36mendheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1275\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1276\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ckelaid\\Anaconda3\\envs\\scrape\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1035\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1036\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1037\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ckelaid\\Anaconda3\\envs\\scrape\\lib\\http\\client.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    975\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 976\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    977\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ckelaid\\Anaconda3\\envs\\scrape\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m         \u001b[0mconn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_prepare_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ckelaid\\Anaconda3\\envs\\scrape\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    186\u001b[0m             raise NewConnectionError(\n\u001b[1;32m--> 187\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Failed to establish a new connection: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m             )\n",
      "\u001b[1;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x000001D9D0999588>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3324\\3971382243.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    279\u001b[0m                         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m                             \u001b[1;32mif\u001b[0m \u001b[0mdel_div\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'We require users to verify the reCaptcha below to view deleted positions'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    281\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ckelaid\\Anaconda3\\envs\\scrape\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001b[0m in \u001b[0;36mtext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[1;34m\"\"\"The text of the element.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_execute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGET_ELEMENT_TEXT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ckelaid\\Anaconda3\\envs\\scrape\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001b[0m in \u001b[0;36m_execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    409\u001b[0m         \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"id\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 410\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ckelaid\\Anaconda3\\envs\\scrape\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 442\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    443\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ckelaid\\Anaconda3\\envs\\scrape\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"{self._url}{path}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 294\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    295\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ckelaid\\Anaconda3\\envs\\scrape\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py\u001b[0m in \u001b[0;36m_request\u001b[1;34m(self, method, url, body)\u001b[0m\n\u001b[0;32m    315\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeep_alive\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m             \u001b[0mstatuscode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ckelaid\\Anaconda3\\envs\\scrape\\lib\\site-packages\\urllib3\\request.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[0;32m     74\u001b[0m             return self.request_encode_url(\n\u001b[1;32m---> 75\u001b[1;33m                 \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfields\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0murlopen_kw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m             )\n",
      "\u001b[1;32mc:\\Users\\ckelaid\\Anaconda3\\envs\\scrape\\lib\\site-packages\\urllib3\\request.py\u001b[0m in \u001b[0;36mrequest_encode_url\u001b[1;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ckelaid\\Anaconda3\\envs\\scrape\\lib\\site-packages\\urllib3\\poolmanager.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[0;32m    375\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 376\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest_uri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    377\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ckelaid\\Anaconda3\\envs\\scrape\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    827\u001b[0m                 \u001b[0mbody_pos\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody_pos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m                 \u001b[1;33m**\u001b[0m\u001b[0mresponse_kw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m             )\n",
      "\u001b[1;32mc:\\Users\\ckelaid\\Anaconda3\\envs\\scrape\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    827\u001b[0m                 \u001b[0mbody_pos\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody_pos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m                 \u001b[1;33m**\u001b[0m\u001b[0mresponse_kw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m             )\n",
      "\u001b[1;32mc:\\Users\\ckelaid\\Anaconda3\\envs\\scrape\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    827\u001b[0m                 \u001b[0mbody_pos\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody_pos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m                 \u001b[1;33m**\u001b[0m\u001b[0mresponse_kw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m             )\n",
      "\u001b[1;32mc:\\Users\\ckelaid\\Anaconda3\\envs\\scrape\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    787\u001b[0m             retries = retries.increment(\n\u001b[1;32m--> 788\u001b[1;33m                 \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    789\u001b[0m             )\n",
      "\u001b[1;32mc:\\Users\\ckelaid\\Anaconda3\\envs\\scrape\\lib\\site-packages\\urllib3\\util\\retry.py\u001b[0m in \u001b[0;36mincrement\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    591\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 592\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    593\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='localhost', port=59676): Max retries exceeded with url: /session/83babc504599544fbaaca41b8748c8ce/element/a8d6d914-8dc5-438c-81e2-de447214b191/text (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001D9D0999588>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3324\\3971382243.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    314\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0maa\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m                                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Pausing for five hours!'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m                                 \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m18000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for link in job_links[133:]: #start at job 212, bc job 1 is index 0\n",
    "    t = random.randint(8,10)\n",
    "    time.sleep(t)\n",
    "    browser = dc.initialize_driver()\n",
    "    browser.get(link)\n",
    "\n",
    "    try:\n",
    "        # wait for page to load\n",
    "        WebDriverWait(browser, 20).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, 'row'))\n",
    "        )\n",
    "        del_div = browser.find_elements(By.CLASS_NAME, 'row')\n",
    "        # Check if post has been deleted\n",
    "        if del_div[6].text != 'We require users to verify the reCaptcha below to view deleted positions.\\nRelated Searches:\\nBusiness and Financial Services\\nCreate your free job search account\\nReceive new jobs by email\\nPost your resume/CV\\nTrack your applications\\nJoin Now\\nHave an account? Sign in':\n",
    "\n",
    "            job_title = browser.find_element(By.ID, 'jobtitle-header').text\n",
    "            job_loc = browser.find_element(By.CLASS_NAME, 'job-loc').text\n",
    "            div = browser.find_elements(By.ID, 'jobAttrib')\n",
    "            job_attr = div[0].find_element(By.CLASS_NAME, 'job-info').text.split('\\n') # get job data\n",
    "       \n",
    "            div = browser.find_elements(By.ID, 'job')\n",
    "            job_desc = div[0].find_element(By.ID, 'jobDesc').text#.split('\\n')\n",
    "            \n",
    "            job_attr = [job_title] + [job_loc] + job_attr # puts title at the begining of the list\n",
    "            job_attr.append(job_desc) # Append job_description\n",
    "            job_attrs.append(job_attr) # Append job details as list inside another list \n",
    "            \n",
    "            scraped = scraped + 1\n",
    "\n",
    "            browser.quit()\n",
    "            smile = smile +1\n",
    "            if smile == 1:\n",
    "                print('\\nScraping away...\\n')\n",
    "                print('0  0\\n')\n",
    "                print('\\__/\\n')\n",
    "            if smile % 100 == 0:\n",
    "                print(\"{} jobs have been scraped so far...\\n\".format(scraped))\n",
    "                print('0  0\\n')\n",
    "                print('\\__/\\n')\n",
    "            \n",
    "            # Save progress (every job info)\n",
    "            #if smile % 500 == 0: # Every 500 jobs save as pickle\n",
    "                # Store data (serialize)\n",
    "            with open('Job_Attrs_'+category+'.pkl', 'wb') as f:\n",
    "                pickle.dump(job_attrs, f)\n",
    "\n",
    "        elif IndexError:\n",
    "            print('\\nJob {} has been deleted'.format(smile))\n",
    "            not_scraped = not_scraped + 1\n",
    "\n",
    "            browser.quit()\n",
    "            smile = smile +1\n",
    "            if smile == 1:\n",
    "                print('\\nScraping away...\\n')\n",
    "                print('0  0\\n')\n",
    "                print('\\__/\\n')\n",
    "            if smile % 100 == 0:\n",
    "                print(\"{} jobs have been scraped so far...\\n\".format(scraped))\n",
    "                print('0  0\\n')\n",
    "                print('\\__/\\n')\n",
    "            \n",
    "            # Save progress (every job info)\n",
    "            #if smile % 500 == 0: # Every 500 jobs save as pickle\n",
    "                # Store data (serialize)\n",
    "            with open('Job_Attrs_'+category+'.pkl', 'wb') as f:\n",
    "                pickle.dump(job_attrs, f)\n",
    "\n",
    "    except Exception: # If cannot find element\n",
    "\n",
    "        # # wait for page to load\n",
    "        # WebDriverWait(browser, 20).until(\n",
    "        #     EC.presence_of_element_located((By.CLASS_NAME, 'iframe'))\n",
    "        # ) \n",
    "               \n",
    "        # See if exception is related to captcha\n",
    "        if browser.find_elements(By.TAG_NAME,'iframe')[0].text.startswith('Request unsuccessful.'):\n",
    "            \n",
    "            #bypassFullCaptcha()\n",
    "            bypassCaptcha1()\n",
    "            \n",
    "            # Check if we get second captcha check\n",
    "            if browser.find_elements(By.TAG_NAME,'iframe')[0].text.startswith('Request unsuccessful.'):\n",
    "                \n",
    "                bypassCaptcha2()\n",
    "                time.sleep(10)\n",
    "        \n",
    "        try:\n",
    "            print('Looking for job info {}\\n'.format(smile))\n",
    "            print('\\nNot scraped is', not_scraped)\n",
    "            # Successfully moved out of Captcha\n",
    "\n",
    "            # wait for page to load\n",
    "            WebDriverWait(browser, 20).until(\n",
    "                EC.presence_of_element_located((By.CLASS_NAME, 'row'))\n",
    "            )\n",
    "            del_div = browser.find_elements(By.CLASS_NAME, 'row')\n",
    "            # Check if post has been deleted\n",
    "            if del_div[6].text != 'We require users to verify the reCaptcha below to view deleted positions.\\nRelated Searches:\\nBusiness and Financial Services\\nCreate your free job search account\\nReceive new jobs by email\\nPost your resume/CV\\nTrack your applications\\nJoin Now\\nHave an account? Sign in':\n",
    "\n",
    "                job_title = browser.find_element(By.ID, 'jobtitle-header').text\n",
    "                job_loc = browser.find_element(By.CLASS_NAME, 'job-loc').text\n",
    "                div = browser.find_elements(By.ID, 'jobAttrib')\n",
    "                job_attr = div[0].find_element(By.CLASS_NAME, 'job-info').text.split('\\n') # get job data\n",
    "                        #job_attr = [job_title] + job_attr\n",
    "                div = browser.find_elements(By.ID, 'job')\n",
    "                job_desc = div[0].find_element(By.ID, 'jobDesc').text#.split('\\n')\n",
    "                    #job_attr.append(job_desc)\n",
    "                    #job_attrs.append(job_attr)\n",
    "                \n",
    "            #else: # if post is delete\n",
    "                job_attr = [job_title] + [job_loc] + job_attr # puts title at the begining of the list\n",
    "                job_attr.append(job_desc) # Append job_description\n",
    "                job_attrs.append(job_attr) # Append job details as list inside another list \n",
    "                \n",
    "                scraped = scraped + 1\n",
    "                \n",
    "                browser.quit()\n",
    "                smile = smile +1\n",
    "                if smile == 1:\n",
    "                    print('\\nScraping away...\\n')\n",
    "                    print('0  0\\n')\n",
    "                    print('\\__/\\n')\n",
    "                if smile % 100 == 0:\n",
    "                    print(\"{} jobs have been scraped so far...\\n\".format(scraped))\n",
    "                    print('0  0\\n')\n",
    "                    print('\\__/\\n')\n",
    "                \n",
    "                # Save progress (every job info)\n",
    "                #if smile % 500 == 0: # Every 500 jobs save as pickle\n",
    "                    # Store data (serialize)\n",
    "                with open('Job_Attrs_'+category+'.pkl', 'wb') as f:\n",
    "                    pickle.dump(job_attrs, f)\n",
    "\n",
    "            elif IndexError:\n",
    "                print('\\nJob {} has been deleted'.format(smile))\n",
    "                not_scraped = not_scraped + 1\n",
    "\n",
    "                browser.quit()\n",
    "                smile = smile +1\n",
    "                if smile == 1:\n",
    "                    print('\\nScraping away...\\n')\n",
    "                    print('0  0\\n')\n",
    "                    print('\\__/\\n')\n",
    "                if smile % 100 == 0:\n",
    "                    print(\"{} jobs have been scraped so far...\\n\".format(scraped))\n",
    "                    print('0  0\\n')\n",
    "                    print('\\__/\\n')\n",
    "                \n",
    "                # Save progress (every job info)\n",
    "                #if smile % 500 == 0: # Every 500 jobs save as pickle\n",
    "                    # Store data (serialize)\n",
    "                with open('Job_Attrs_'+category+'.pkl', 'wb') as f:\n",
    "                    pickle.dump(job_attrs, f)\n",
    "            \n",
    "        except Exception:\n",
    "\n",
    "            try:\n",
    "                if del_div[6].text.startswith('We require users to verify the reCaptcha below to view deleted positions'):\n",
    "                    \n",
    "                    print('\\nJob {} has been deleted'.format(smile))\n",
    "                    not_scraped = not_scraped + 1\n",
    "\n",
    "                    browser.quit()\n",
    "                    smile = smile +1\n",
    "                    if smile == 1:\n",
    "                        print('\\nScraping away...\\n')\n",
    "                        print('0  0\\n')\n",
    "                        print('\\__/\\n')\n",
    "                    if smile % 100 == 0:\n",
    "                        print(\"{} jobs have been scraped so far...\\n\".format(scraped))\n",
    "                        print('0  0\\n')\n",
    "                        print('\\__/\\n')\n",
    "                    \n",
    "                    # Save progress (every job info)\n",
    "                    #if smile % 500 == 0: # Every 500 jobs save as pickle\n",
    "                        # Store data (serialize)\n",
    "                    with open('Job_Attrs_'+category+'.pkl', 'wb') as f:\n",
    "                        pickle.dump(job_attrs, f)\n",
    "            \n",
    "            except Exception:\n",
    "            # If exception is not b/c job is deleted then we need to pause\n",
    "                # API limit exceeded and need to wait, pause 20 minutes and try again\n",
    "                browser.quit()\n",
    "                print('Pausing 20 minutes, buster API overused!')\n",
    "                time.sleep(1200) # wait 20 minutes :( looooooong\n",
    "\n",
    "                pp = 0\n",
    "                aa = 0\n",
    "                while pp < 1:\n",
    "                    try:\n",
    "                        browser = dc.initialize_driver()\n",
    "                        browser.get(link)\n",
    "\n",
    "                        #browser.switch_to.default_content()\n",
    "                        \n",
    "                        if browser.find_elements(By.TAG_NAME,'iframe')[0].text.startswith('Request unsuccessful.'):\n",
    "                            print('Trying again on job ', smile)\n",
    "\n",
    "                            time.sleep(10)\n",
    "\n",
    "                            bypassCaptcha1()\n",
    "\n",
    "                            bypassCaptcha2()\n",
    "                            time.sleep(10)\n",
    "\n",
    "                            print('Looking for job info {}\\n'.format(smile))\n",
    "                            print('\\nNot scraped is', not_scraped)\n",
    "                                \n",
    "                            # Successfully moved out of Captcha\n",
    "\n",
    "                            # wait for page to load\n",
    "                            WebDriverWait(browser, 20).until(\n",
    "                                EC.presence_of_element_located((By.CLASS_NAME, 'row'))\n",
    "                            )\n",
    "                            del_div = browser.find_elements(By.CLASS_NAME, 'row')\n",
    "                            # Check if post has been deleted\n",
    "                            if del_div[6].text != 'We require users to verify the reCaptcha below to view deleted positions.\\nRelated Searches:\\nBusiness and Financial Services\\nCreate your free job search account\\nReceive new jobs by email\\nPost your resume/CV\\nTrack your applications\\nJoin Now\\nHave an account? Sign in':\n",
    "\n",
    "                                job_title = browser.find_element(By.ID, 'jobtitle-header').text\n",
    "                                job_loc = browser.find_element(By.CLASS_NAME, 'job-loc').text\n",
    "                                div = browser.find_elements(By.ID, 'jobAttrib')\n",
    "                                job_attr = div[0].find_element(By.CLASS_NAME, 'job-info').text.split('\\n') # get job data\n",
    "                                        #job_attr = [job_title] + job_attr\n",
    "                                div = browser.find_elements(By.ID, 'job')\n",
    "                                job_desc = div[0].find_element(By.ID, 'jobDesc').text#.split('\\n')\n",
    "                                    #job_attr.append(job_desc)\n",
    "                                    #job_attrs.append(job_attr)\n",
    "                                \n",
    "                            #else: # if post is delete\n",
    "                                job_attr = [job_title] + [job_loc] + job_attr # puts title at the begining of the list\n",
    "                                job_attr.append(job_desc) # Append job_description\n",
    "                                job_attrs.append(job_attr) # Append job details as list inside another list \n",
    "                                \n",
    "                                scraped = scraped + 1\n",
    "                                \n",
    "                                browser.quit()\n",
    "                                smile = smile +1\n",
    "                                if smile == 1:\n",
    "                                    print('\\nScraping away...\\n')\n",
    "                                    print('0  0\\n')\n",
    "                                    print('\\__/\\n')\n",
    "                                if smile % 100 == 0:\n",
    "                                    print(\"{} jobs have been scraped so far...\\n\".format(scraped))\n",
    "                                    print('0  0\\n')\n",
    "                                    print('\\__/\\n')\n",
    "                                \n",
    "                                # Save progress (every job info)\n",
    "                                #if smile % 500 == 0: # Every 500 jobs save as pickle\n",
    "                                    # Store data (serialize)\n",
    "                                with open('Job_Attrs_'+category+'.pkl', 'wb') as f:\n",
    "                                    pickle.dump(job_attrs, f)\n",
    "                                pp = 1\n",
    "\n",
    "                            elif IndexError:\n",
    "                                print('\\nJob {} has been deleted'.format(smile))\n",
    "                                not_scraped = not_scraped + 1\n",
    "\n",
    "                                browser.quit()\n",
    "                                smile = smile +1\n",
    "                                if smile == 1:\n",
    "                                    print('\\nScraping away...\\n')\n",
    "                                    print('0  0\\n')\n",
    "                                    print('\\__/\\n')\n",
    "                                if smile % 100 == 0:\n",
    "                                    print(\"{} jobs have been scraped so far...\\n\".format(scraped))\n",
    "                                    print('0  0\\n')\n",
    "                                    print('\\__/\\n')\n",
    "                                \n",
    "                                # Save progress (every job info)\n",
    "                                #if smile % 500 == 0: # Every 500 jobs save as pickle\n",
    "                                    # Store data (serialize)\n",
    "                                with open('Job_Attrs_'+category+'.pkl', 'wb') as f:\n",
    "                                    pickle.dump(job_attrs, f)\n",
    "                                pp = 1\n",
    "                            \n",
    "                                \n",
    "                    except Exception:\n",
    "                        time.sleep(60)\n",
    "                        try:\n",
    "                            if del_div[6].text.startswith('We require users to verify the reCaptcha below to view deleted positions'):\n",
    "                    \n",
    "                                print('\\nJob {} has been deleted'.format(smile))\n",
    "                                not_scraped = not_scraped + 1\n",
    "\n",
    "                                browser.quit()\n",
    "                                smile = smile +1\n",
    "                                if smile == 1:\n",
    "                                    print('\\nScraping away...\\n')\n",
    "                                    print('0  0\\n')\n",
    "                                    print('\\__/\\n')\n",
    "                                if smile % 100 == 0:\n",
    "                                    print(\"{} jobs have been scraped so far...\\n\".format(scraped))\n",
    "                                    print('0  0\\n')\n",
    "                                    print('\\__/\\n')\n",
    "                                \n",
    "                                # Save progress (every job info)\n",
    "                                #if smile % 500 == 0: # Every 500 jobs save as pickle\n",
    "                                    # Store data (serialize)\n",
    "                                with open('Job_Attrs_'+category+'.pkl', 'wb') as f:\n",
    "                                    pickle.dump(job_attrs, f)\n",
    "                                pp = 1\n",
    "                        \n",
    "                        except Exception:\n",
    "\n",
    "                            browser.implicitly_wait(7)\n",
    "                            browser.quit()\n",
    "                            pp = 0\n",
    "                            aa = aa + 1\n",
    "                            print('\\naa is \\n', aa)\n",
    "                            if aa == 5: #Let it try a few times\n",
    "                                print('Pausing for 30 minutes')\n",
    "                                time.sleep(1800) \n",
    "                            \n",
    "                            if aa > 5:\n",
    "                                print('Pausing for five hours!')\n",
    "                                time.sleep(18000)\n",
    "                    \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        # else: # if exception not related to captcha, than simply info doesn't exist\n",
    "        #     not_scraped = not_scraped + 1\n",
    "\n",
    "if not_scraped > 0:\n",
    "\n",
    "    if not_scraped == 1:\n",
    "        print('Unfortunately, information for {} job was unable to be scraped.'.format(not_scraped))\n",
    "    \n",
    "    elif not_scraped > 1:\n",
    "        print('Unfortunately, information for {} jobs was unable to be scraped.'.format(not_scraped))\n",
    "\n",
    "print(\"\\nInformation on a total of {} jobs has been scraped\\n\".format(scraped))\n",
    "\n",
    "print(\"\\nLenght of job_attrs is: {}\\n\".format(len(job_attrs)))\n",
    "\n",
    "# # Store in dictionary\n",
    "# for i in range(len(job_attrs)):\n",
    "#     job_dict['Job ' + str(i+1)] = job_attrs[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'IT_Support_and_Training'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job link\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job link\n",
      "\n",
      "Pausing 20 minutes, buster API overused!\n",
      "Trying again\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job link\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job link\n",
      "\n",
      "Pausing 20 minutes, buster API overused!\n",
      "Trying again\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job link\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job link\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job link\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job link\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job link\n",
      "\n",
      "Pausing 20 minutes, buster API overused!\n",
      "Trying again\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job link\n",
      "\n",
      "Trying again\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job link\n",
      "\n",
      "Trying again\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job link\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job link\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job link\n",
      "\n",
      "Job_links:  1104\n",
      "There are 1093 jobs to scrape\n",
      "Job_links:  1093\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 0\n",
      "\n",
      "\n",
      "Not scraped is 0\n",
      "\n",
      "Scraping away...\n",
      "\n",
      "0  0\n",
      "\n",
      "\\__/\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 1\n",
      "\n",
      "\n",
      "Not scraped is 0\n",
      "Pausing 20 minutes, buster API overused!\n",
      "Trying again on job  1\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 1\n",
      "\n",
      "\n",
      "Not scraped is 0\n",
      "\n",
      "aa is \n",
      " 1\n",
      "Trying again on job  1\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 1\n",
      "\n",
      "\n",
      "Not scraped is 0\n",
      "\n",
      "aa is \n",
      " 2\n",
      "Trying again on job  1\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 1\n",
      "\n",
      "\n",
      "Not scraped is 0\n",
      "\n",
      "aa is \n",
      " 3\n",
      "Trying again on job  1\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 1\n",
      "\n",
      "\n",
      "Not scraped is 0\n",
      "\n",
      "aa is \n",
      " 4\n",
      "Trying again on job  1\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 1\n",
      "\n",
      "\n",
      "Not scraped is 0\n",
      "\n",
      "aa is \n",
      " 5\n",
      "Pausing for 30 minutes\n",
      "Trying again on job  1\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 1\n",
      "\n",
      "\n",
      "Not scraped is 0\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 2\n",
      "\n",
      "\n",
      "Not scraped is 0\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 3\n",
      "\n",
      "\n",
      "Not scraped is 0\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 4\n",
      "\n",
      "\n",
      "Not scraped is 0\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 5\n",
      "\n",
      "\n",
      "Not scraped is 0\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 6\n",
      "\n",
      "\n",
      "Not scraped is 0\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 7\n",
      "\n",
      "\n",
      "Not scraped is 0\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 8\n",
      "\n",
      "\n",
      "Not scraped is 0\n",
      "Pausing 20 minutes, buster API overused!\n",
      "Trying again on job  8\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 8\n",
      "\n",
      "\n",
      "Not scraped is 0\n",
      "\n",
      "aa is \n",
      " 1\n",
      "Trying again on job  8\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 8\n",
      "\n",
      "\n",
      "Not scraped is 0\n",
      "\n",
      "aa is \n",
      " 2\n",
      "Trying again on job  8\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 8\n",
      "\n",
      "\n",
      "Not scraped is 0\n",
      "\n",
      "aa is \n",
      " 3\n",
      "Trying again on job  8\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 8\n",
      "\n",
      "\n",
      "Not scraped is 0\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 9\n",
      "\n",
      "\n",
      "Not scraped is 0\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 10\n",
      "\n",
      "\n",
      "Not scraped is 0\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 11\n",
      "\n",
      "\n",
      "Not scraped is 0\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 12\n",
      "\n",
      "\n",
      "Not scraped is 0\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 13\n",
      "\n",
      "\n",
      "Not scraped is 0\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 14\n",
      "\n",
      "\n",
      "Not scraped is 0\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 15\n",
      "\n",
      "\n",
      "Not scraped is 0\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 16\n",
      "\n",
      "\n",
      "Not scraped is 0\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 17\n",
      "\n",
      "\n",
      "Not scraped is 0\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 18\n",
      "\n",
      "\n",
      "Not scraped is 0\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 19\n",
      "\n",
      "\n",
      "Not scraped is 0\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 20\n",
      "\n",
      "\n",
      "Not scraped is 0\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 21\n",
      "\n",
      "\n",
      "Not scraped is 0\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 22\n",
      "\n",
      "\n",
      "Not scraped is 0\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 23\n",
      "\n",
      "\n",
      "Not scraped is 0\n",
      "Pausing 20 minutes, buster API overused!\n",
      "Trying again on job  23\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 23\n",
      "\n",
      "\n",
      "Not scraped is 0\n",
      "\n",
      "aa is \n",
      " 1\n",
      "Trying again on job  23\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 23\n",
      "\n",
      "\n",
      "Not scraped is 0\n",
      "\n",
      "aa is \n",
      " 2\n",
      "Trying again on job  23\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 23\n",
      "\n",
      "\n",
      "Not scraped is 0\n",
      "\n",
      "aa is \n",
      " 3\n",
      "Trying again on job  23\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 23\n",
      "\n",
      "\n",
      "Not scraped is 0\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 24\n",
      "\n",
      "\n",
      "Not scraped is 0\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 25\n",
      "\n",
      "\n",
      "Not scraped is 0\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 26\n",
      "\n",
      "\n",
      "Not scraped is 0\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 27\n",
      "\n",
      "\n",
      "Not scraped is 0\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 28\n",
      "\n",
      "\n",
      "Not scraped is 0\n",
      "Pausing 20 minutes, buster API overused!\n",
      "Trying again on job  28\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 28\n",
      "\n",
      "\n",
      "Not scraped is 0\n",
      "\n",
      "aa is \n",
      " 1\n",
      "Trying again on job  28\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 28\n",
      "\n",
      "\n",
      "Not scraped is 0\n",
      "\n",
      "aa is \n",
      " 2\n",
      "Trying again on job  28\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 28\n",
      "\n",
      "\n",
      "Not scraped is 0\n",
      "\n",
      "aa is \n",
      " 3\n",
      "Trying again on job  28\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 28\n",
      "\n",
      "\n",
      "Not scraped is 0\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 29\n",
      "\n",
      "\n",
      "Not scraped is 0\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 30\n",
      "\n",
      "\n",
      "Not scraped is 0\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 31\n",
      "\n",
      "\n",
      "Not scraped is 0\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 32\n",
      "\n",
      "\n",
      "Not scraped is 0\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 33\n",
      "\n",
      "\n",
      "Not scraped is 0\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 34\n",
      "\n",
      "\n",
      "Not scraped is 0\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 35\n",
      "\n",
      "\n",
      "Not scraped is 0\n",
      "\n",
      "Job 35 has been deleted\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 36\n",
      "\n",
      "\n",
      "Not scraped is 1\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 37\n",
      "\n",
      "\n",
      "Not scraped is 1\n",
      "Pausing 20 minutes, buster API overused!\n",
      "Trying again on job  37\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 37\n",
      "\n",
      "\n",
      "Not scraped is 1\n",
      "\n",
      "aa is \n",
      " 1\n",
      "Trying again on job  37\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 37\n",
      "\n",
      "\n",
      "Not scraped is 1\n",
      "\n",
      "aa is \n",
      " 2\n",
      "Trying again on job  37\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 37\n",
      "\n",
      "\n",
      "Not scraped is 1\n",
      "\n",
      "aa is \n",
      " 3\n",
      "Trying again on job  37\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 37\n",
      "\n",
      "\n",
      "Not scraped is 1\n",
      "\n",
      "aa is \n",
      " 4\n",
      "Trying again on job  37\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 37\n",
      "\n",
      "\n",
      "Not scraped is 1\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 38\n",
      "\n",
      "\n",
      "Not scraped is 1\n",
      "Pausing 20 minutes, buster API overused!\n",
      "Trying again on job  38\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 38\n",
      "\n",
      "\n",
      "Not scraped is 1\n",
      "\n",
      "aa is \n",
      " 1\n",
      "Trying again on job  38\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 38\n",
      "\n",
      "\n",
      "Not scraped is 1\n",
      "\n",
      "aa is \n",
      " 2\n",
      "Trying again on job  38\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 38\n",
      "\n",
      "\n",
      "Not scraped is 1\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 39\n",
      "\n",
      "\n",
      "Not scraped is 1\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 40\n",
      "\n",
      "\n",
      "Not scraped is 1\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 41\n",
      "\n",
      "\n",
      "Not scraped is 1\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 42\n",
      "\n",
      "\n",
      "Not scraped is 1\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 43\n",
      "\n",
      "\n",
      "Not scraped is 1\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 44\n",
      "\n",
      "\n",
      "Not scraped is 1\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 45\n",
      "\n",
      "\n",
      "Not scraped is 1\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 46\n",
      "\n",
      "\n",
      "Not scraped is 1\n",
      "\n",
      "Job 46 has been deleted\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 47\n",
      "\n",
      "\n",
      "Not scraped is 2\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 48\n",
      "\n",
      "\n",
      "Not scraped is 2\n",
      "Pausing 20 minutes, buster API overused!\n",
      "Trying again on job  48\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 48\n",
      "\n",
      "\n",
      "Not scraped is 2\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 49\n",
      "\n",
      "\n",
      "Not scraped is 2\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 50\n",
      "\n",
      "\n",
      "Not scraped is 2\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 51\n",
      "\n",
      "\n",
      "Not scraped is 2\n",
      "Pausing 20 minutes, buster API overused!\n",
      "Trying again on job  51\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 51\n",
      "\n",
      "\n",
      "Not scraped is 2\n",
      "\n",
      "aa is \n",
      " 1\n",
      "Trying again on job  51\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "aa is \n",
      " 2\n",
      "Trying again on job  51\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 51\n",
      "\n",
      "\n",
      "Not scraped is 2\n",
      "\n",
      "aa is \n",
      " 3\n",
      "Trying again on job  51\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 51\n",
      "\n",
      "\n",
      "Not scraped is 2\n",
      "\n",
      "aa is \n",
      " 4\n",
      "Trying again on job  51\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 51\n",
      "\n",
      "\n",
      "Not scraped is 2\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 52\n",
      "\n",
      "\n",
      "Not scraped is 2\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 53\n",
      "\n",
      "\n",
      "Not scraped is 2\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 54\n",
      "\n",
      "\n",
      "Not scraped is 2\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 55\n",
      "\n",
      "\n",
      "Not scraped is 2\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 56\n",
      "\n",
      "\n",
      "Not scraped is 2\n",
      "Pausing 20 minutes, buster API overused!\n",
      "Trying again on job  56\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 56\n",
      "\n",
      "\n",
      "Not scraped is 2\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 57\n",
      "\n",
      "\n",
      "Not scraped is 2\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 58\n",
      "\n",
      "\n",
      "Not scraped is 2\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 59\n",
      "\n",
      "\n",
      "Not scraped is 2\n",
      "Pausing 20 minutes, buster API overused!\n",
      "Trying again on job  59\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 59\n",
      "\n",
      "\n",
      "Not scraped is 2\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 60\n",
      "\n",
      "\n",
      "Not scraped is 2\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 61\n",
      "\n",
      "\n",
      "Not scraped is 2\n",
      "Pausing 20 minutes, buster API overused!\n",
      "Trying again on job  61\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 61\n",
      "\n",
      "\n",
      "Not scraped is 2\n",
      "\n",
      "aa is \n",
      " 1\n",
      "Trying again on job  61\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 61\n",
      "\n",
      "\n",
      "Not scraped is 2\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 62\n",
      "\n",
      "\n",
      "Not scraped is 2\n",
      "Pausing 20 minutes, buster API overused!\n",
      "Trying again on job  62\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 62\n",
      "\n",
      "\n",
      "Not scraped is 2\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 63\n",
      "\n",
      "\n",
      "Not scraped is 2\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 64\n",
      "\n",
      "\n",
      "Not scraped is 2\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 65\n",
      "\n",
      "\n",
      "Not scraped is 2\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 66\n",
      "\n",
      "\n",
      "Not scraped is 2\n",
      "Pausing 20 minutes, buster API overused!\n",
      "Trying again on job  66\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 66\n",
      "\n",
      "\n",
      "Not scraped is 2\n",
      "\n",
      "aa is \n",
      " 1\n",
      "Trying again on job  66\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 66\n",
      "\n",
      "\n",
      "Not scraped is 2\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 67\n",
      "\n",
      "\n",
      "Not scraped is 2\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 68\n",
      "\n",
      "\n",
      "Not scraped is 2\n",
      "Pausing 20 minutes, buster API overused!\n",
      "Trying again on job  68\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 68\n",
      "\n",
      "\n",
      "Not scraped is 2\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 69\n",
      "\n",
      "\n",
      "Not scraped is 2\n",
      "\n",
      "Job 69 has been deleted\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 70\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "Pausing 20 minutes, buster API overused!\n",
      "Trying again on job  70\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 70\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "aa is \n",
      " 1\n",
      "Trying again on job  70\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 70\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "aa is \n",
      " 2\n",
      "Trying again on job  70\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 70\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 71\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "Pausing 20 minutes, buster API overused!\n",
      "Trying again on job  71\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 71\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 72\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 73\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "Pausing 20 minutes, buster API overused!\n",
      "Trying again on job  73\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 73\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 74\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 75\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 76\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 77\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 78\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 79\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "Pausing 20 minutes, buster API overused!\n",
      "Trying again on job  79\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 79\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 80\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 81\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 82\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "Pausing 20 minutes, buster API overused!\n",
      "Trying again on job  82\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 82\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "aa is \n",
      " 1\n",
      "Trying again on job  82\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 82\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 83\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "Pausing 20 minutes, buster API overused!\n",
      "Trying again on job  83\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 83\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "aa is \n",
      " 1\n",
      "Trying again on job  83\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 83\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 84\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "Pausing 20 minutes, buster API overused!\n",
      "Trying again on job  84\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 84\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 85\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "Pausing 20 minutes, buster API overused!\n",
      "Trying again on job  85\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 85\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "aa is \n",
      " 1\n",
      "Trying again on job  85\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 85\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 86\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 87\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 88\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 89\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 90\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 91\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "Pausing 20 minutes, buster API overused!\n",
      "Trying again on job  91\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 91\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 92\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 93\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 94\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 95\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "Pausing 20 minutes, buster API overused!\n",
      "Trying again on job  95\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 95\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 96\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "Pausing 20 minutes, buster API overused!\n",
      "Trying again on job  96\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 96\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "aa is \n",
      " 1\n",
      "Trying again on job  96\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 96\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "aa is \n",
      " 2\n",
      "Trying again on job  96\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 96\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 97\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "Pausing 20 minutes, buster API overused!\n",
      "Trying again on job  97\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 97\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "aa is \n",
      " 1\n",
      "Trying again on job  97\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 97\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 98\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "Pausing 20 minutes, buster API overused!\n",
      "Trying again on job  98\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 98\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "aa is \n",
      " 1\n",
      "Trying again on job  98\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 98\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 99\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "Pausing 20 minutes, buster API overused!\n",
      "Trying again on job  99\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 99\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "aa is \n",
      " 1\n",
      "Trying again on job  99\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 99\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "97 jobs have been scraped so far...\n",
      "\n",
      "0  0\n",
      "\n",
      "\\__/\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 100\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "Pausing 20 minutes, buster API overused!\n",
      "Trying again on job  100\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 100\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "aa is \n",
      " 1\n",
      "Trying again on job  100\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 100\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 101\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "Pausing 20 minutes, buster API overused!\n",
      "Trying again on job  101\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 101\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 102\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "Pausing 20 minutes, buster API overused!\n",
      "Trying again on job  102\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 102\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 103\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 104\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 105\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 106\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 107\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "Pausing 20 minutes, buster API overused!\n",
      "Trying again on job  107\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 107\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "aa is \n",
      " 1\n",
      "Trying again on job  107\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 107\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "aa is \n",
      " 2\n",
      "Trying again on job  107\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 107\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 108\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "Pausing 20 minutes, buster API overused!\n",
      "Trying again on job  108\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 108\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 109\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "Pausing 20 minutes, buster API overused!\n",
      "Trying again on job  109\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 109\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 110\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "Pausing 20 minutes, buster API overused!\n",
      "Trying again on job  110\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 110\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "aa is \n",
      " 1\n",
      "Trying again on job  110\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 110\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "aa is \n",
      " 2\n",
      "Trying again on job  110\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 110\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "aa is \n",
      " 3\n",
      "Trying again on job  110\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 110\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "aa is \n",
      " 4\n",
      "Trying again on job  110\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 110\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "aa is \n",
      " 5\n",
      "Pausing for 30 minutes\n",
      "Trying again on job  110\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 110\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "aa is \n",
      " 6\n",
      "Pausing for five hours!\n",
      "Trying again on job  110\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 110\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "aa is \n",
      " 7\n",
      "Pausing for five hours!\n",
      "Trying again on job  110\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 110\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 111\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 112\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 113\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 114\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 115\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 116\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 117\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "Pausing 20 minutes, buster API overused!\n",
      "Trying again on job  117\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 117\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 118\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "Pausing 20 minutes, buster API overused!\n",
      "Trying again on job  118\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 118\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 119\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 120\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "Pausing 20 minutes, buster API overused!\n",
      "Trying again on job  120\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 120\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "aa is \n",
      " 1\n",
      "Trying again on job  120\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 120\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 121\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 122\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 123\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "Pausing 20 minutes, buster API overused!\n",
      "Trying again on job  123\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 123\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "aa is \n",
      " 1\n",
      "Trying again on job  123\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 123\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "aa is \n",
      " 2\n",
      "Trying again on job  123\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 123\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 124\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 125\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 126\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 127\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 128\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 129\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 130\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 131\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 132\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n",
      "\n",
      "Successfuly bypassed Captcha 2!\n",
      "\n",
      "Looking for job info 133\n",
      "\n",
      "\n",
      "Not scraped is 3\n",
      "\n",
      "Successfuly bypassed Captcha 1!\n",
      "\n"
     ]
    },
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//div[@class=\"button-holder help-button-holder\"]\"}\n  (Session info: chrome=110.0.5481.178)\nStacktrace:\nBacktrace:\n\t(No symbol) [0x00B86643]\n\t(No symbol) [0x00B1BE21]\n\t(No symbol) [0x00A1DA9D]\n\t(No symbol) [0x00A51342]\n\t(No symbol) [0x00A5147B]\n\t(No symbol) [0x00A88DC2]\n\t(No symbol) [0x00A6FDC4]\n\t(No symbol) [0x00A86B09]\n\t(No symbol) [0x00A6FB76]\n\t(No symbol) [0x00A449C1]\n\t(No symbol) [0x00A45E5D]\n\tGetHandleVerifier [0x00DFA142+2497106]\n\tGetHandleVerifier [0x00E285D3+2686691]\n\tGetHandleVerifier [0x00E2BB9C+2700460]\n\tGetHandleVerifier [0x00C33B10+635936]\n\t(No symbol) [0x00B24A1F]\n\t(No symbol) [0x00B2A418]\n\t(No symbol) [0x00B2A505]\n\t(No symbol) [0x00B3508B]\n\tBaseThreadInitThunk [0x763900F9+25]\n\tRtlGetAppContainerNamedObjectPath [0x77237BBE+286]\n\tRtlGetAppContainerNamedObjectPath [0x77237B8E+238]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3324\\1408859066.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    175\u001b[0m         WebDriverWait(browser, 20).until(\n\u001b[1;32m--> 176\u001b[1;33m             \u001b[0mEC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpresence_of_element_located\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCLASS_NAME\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'row'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m         )\n",
      "\u001b[1;32mc:\\Users\\ckelaid\\Anaconda3\\envs\\scrape\\lib\\site-packages\\selenium\\webdriver\\support\\wait.py\u001b[0m in \u001b[0;36muntil\u001b[1;34m(self, method, message)\u001b[0m\n\u001b[0;32m     94\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTimeoutException\u001b[0m: Message: \nStacktrace:\nBacktrace:\n\t(No symbol) [0x00B86643]\n\t(No symbol) [0x00B1BE21]\n\t(No symbol) [0x00A1DA9D]\n\t(No symbol) [0x00A51342]\n\t(No symbol) [0x00A5147B]\n\t(No symbol) [0x00A88DC2]\n\t(No symbol) [0x00A6FDC4]\n\t(No symbol) [0x00A86B09]\n\t(No symbol) [0x00A6FB76]\n\t(No symbol) [0x00A449C1]\n\t(No symbol) [0x00A45E5D]\n\tGetHandleVerifier [0x00DFA142+2497106]\n\tGetHandleVerifier [0x00E285D3+2686691]\n\tGetHandleVerifier [0x00E2BB9C+2700460]\n\tGetHandleVerifier [0x00C33B10+635936]\n\t(No symbol) [0x00B24A1F]\n\t(No symbol) [0x00B2A418]\n\t(No symbol) [0x00B2A505]\n\t(No symbol) [0x00B3508B]\n\tBaseThreadInitThunk [0x763900F9+25]\n\tRtlGetAppContainerNamedObjectPath [0x77237BBE+286]\n\tRtlGetAppContainerNamedObjectPath [0x77237B8E+238]\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3324\\1408859066.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    248\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbrowser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_elements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTAG_NAME\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'iframe'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Request unsuccessful.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m                 \u001b[0mbypassCaptcha2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    251\u001b[0m                 \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3324\\1753440354.py\u001b[0m in \u001b[0;36mbypassCaptcha2\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mbrowser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswitch_to\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miframe3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m# Find nearest element to #shadow-root (closed)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0melem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbrowser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'//div[@class=\"button-holder help-button-holder\"]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mbrowser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimplicitly_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# click on it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ckelaid\\Anaconda3\\envs\\scrape\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    859\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'[name=\"%s\"]'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFIND_ELEMENT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"using\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"value\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_elements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mWebElement\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ckelaid\\Anaconda3\\envs\\scrape\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    442\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 444\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    445\u001b[0m             \u001b[0mresponse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unwrap_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ckelaid\\Anaconda3\\envs\\scrape\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    247\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"alert\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"text\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//div[@class=\"button-holder help-button-holder\"]\"}\n  (Session info: chrome=110.0.5481.178)\nStacktrace:\nBacktrace:\n\t(No symbol) [0x00B86643]\n\t(No symbol) [0x00B1BE21]\n\t(No symbol) [0x00A1DA9D]\n\t(No symbol) [0x00A51342]\n\t(No symbol) [0x00A5147B]\n\t(No symbol) [0x00A88DC2]\n\t(No symbol) [0x00A6FDC4]\n\t(No symbol) [0x00A86B09]\n\t(No symbol) [0x00A6FB76]\n\t(No symbol) [0x00A449C1]\n\t(No symbol) [0x00A45E5D]\n\tGetHandleVerifier [0x00DFA142+2497106]\n\tGetHandleVerifier [0x00E285D3+2686691]\n\tGetHandleVerifier [0x00E2BB9C+2700460]\n\tGetHandleVerifier [0x00C33B10+635936]\n\t(No symbol) [0x00B24A1F]\n\t(No symbol) [0x00B2A418]\n\t(No symbol) [0x00B2A505]\n\t(No symbol) [0x00B3508B]\n\tBaseThreadInitThunk [0x763900F9+25]\n\tRtlGetAppContainerNamedObjectPath [0x77237BBE+286]\n\tRtlGetAppContainerNamedObjectPath [0x77237B8E+238]\n"
     ]
    }
   ],
   "source": [
    "# Scraping job links + cleaning job links + scraping job attributes\n",
    "\n",
    "for link in page_links:\n",
    "    t = random.randint(8,10)\n",
    "    time.sleep(t)\n",
    "    browser = dc.initialize_driver()\n",
    "    browser.get(link)\n",
    "    try:\n",
    "        # wait for page to load\n",
    "        WebDriverWait(browser, 20).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, 'col-sm-7'))\n",
    "        )\n",
    "        # get job links\n",
    "        div = browser.find_elements(By.CLASS_NAME, 'col-sm-7')\n",
    "        for d in div:\n",
    "            job_links.append(d.find_element(By.CSS_SELECTOR, 'a').get_attribute('href'))\n",
    "        browser.quit()\n",
    "        with open('Job_links_'+category+'.pkl', 'wb') as f:\n",
    "            pickle.dump(job_links, f)\n",
    "    except Exception:\n",
    "        # print('bypassing Captcha')\n",
    "        # WebDriverWait(browser, 10).until(\n",
    "        #     EC.presence_of_all_elements_located((By.TAG_NAME,'iframe'))\n",
    "        # )\n",
    "        # Check that exception is b/c of Captcha\n",
    "        if browser.find_elements(By.TAG_NAME,'iframe')[0].text.startswith('Request unsuccessful.'):\n",
    "\n",
    "            #bypassFullCaptcha()\n",
    "            bypassCaptcha1()\n",
    "            \n",
    "            # Check if we get second captcha check\n",
    "            if browser.find_elements(By.TAG_NAME,'iframe')[0].text.startswith('Request unsuccessful.'):\n",
    "                \n",
    "                bypassCaptcha2()\n",
    "                time.sleep(10)\n",
    "\n",
    "        try:\n",
    "            print('Looking for job link\\n')\n",
    "                \n",
    "            # Successfully moved out of Captcha\n",
    "\n",
    "            # wait for page to load\n",
    "            WebDriverWait(browser, 20).until(\n",
    "                    EC.presence_of_element_located((By.CLASS_NAME, 'col-sm-7'))\n",
    "            ) \n",
    "            # get job links\n",
    "            div = browser.find_elements(By.CLASS_NAME, 'col-sm-7')\n",
    "            for d in div:\n",
    "                job_links.append(d.find_element(By.CSS_SELECTOR, 'a').get_attribute('href'))\n",
    "            browser.quit()\n",
    "            with open('Job_links_'+category+'.pkl', 'wb') as f:\n",
    "                pickle.dump(job_links, f)\n",
    "        \n",
    "        except Exception:\n",
    "            # API limit exceeded and need to wait, pause 20 minutes and try again\n",
    "            browser.quit()\n",
    "            print('Pausing 20 minutes, buster API overused!')\n",
    "            time.sleep(1200) # wait 20 minutes :( looooooong\n",
    "\n",
    "            pp = 0\n",
    "            aa = 0\n",
    "            while pp < 1:\n",
    "                try:\n",
    "                    browser = dc.initialize_driver()\n",
    "                    browser.get(link)\n",
    "\n",
    "                    #browser.switch_to.default_content()\n",
    "                    \n",
    "                    if browser.find_elements(By.TAG_NAME,'iframe')[0].text.startswith('Request unsuccessful.'):\n",
    "                        print('Trying again')\n",
    "\n",
    "                        time.sleep(10)\n",
    "\n",
    "                        bypassCaptcha1()\n",
    "\n",
    "                        # Check if we get second captcha check\n",
    "                        if browser.find_elements(By.TAG_NAME,'iframe')[0].text.startswith('Request unsuccessful.'):\n",
    "\n",
    "                            bypassCaptcha2()\n",
    "                            time.sleep(10)\n",
    "\n",
    "                        print('Looking for job link\\n')\n",
    "                            \n",
    "                        # Successfully moved out of Captcha\n",
    "\n",
    "                        # wait for page to load\n",
    "                        WebDriverWait(browser, 20).until(\n",
    "                                EC.presence_of_element_located((By.CLASS_NAME, 'col-sm-7'))\n",
    "                        ) \n",
    "                        # get job links\n",
    "                        div = browser.find_elements(By.CLASS_NAME, 'col-sm-7')\n",
    "                        for d in div:\n",
    "                            job_links.append(d.find_element(By.CSS_SELECTOR, 'a').get_attribute('href'))\n",
    "                        browser.quit()\n",
    "                        with open('Job_links_'+category+'.pkl', 'wb') as f:\n",
    "                            pickle.dump(job_links, f)\n",
    "                        pp = 1\n",
    "                    \n",
    "                except Exception:\n",
    "                    time.sleep(60)\n",
    "                    browser.implicitly_wait(7)\n",
    "                    browser.quit()\n",
    "                    pp = 0\n",
    "                    aa = aa+1\n",
    "                    if aa == 5:\n",
    "                        print('Pausing for 30')\n",
    "                        time.sleep(1800) # 30 minutes\n",
    "                    \n",
    "                    if aa > 5:\n",
    "                        print('Pausing for 5 hours!')\n",
    "                        time.sleep(18000)\n",
    "\n",
    "# Done with job links\n",
    "print(\"Job_links: \",len(job_links))\n",
    "\n",
    "######################################\n",
    "\n",
    "# Cleaning job_links\n",
    "\n",
    "######################################\n",
    "\n",
    "# Deleting wrong entries\n",
    "del_ix = []\n",
    "for i in range(len(job_links)):\n",
    "    if job_links[i] == 'javascript:;':\n",
    "        del_ix.append(i) \n",
    "\n",
    "# Also check that no job_links == category_page url\n",
    "for j in range(len(job_links)):\n",
    "    if job_links[j] == 'https://www.higheredjobs.com/admin/search.cfm?JobCat='+cat_num+'&SortBy=4&StartRow=1':\n",
    "        del_ix.append(j)\n",
    "\n",
    "if len(del_ix) > 0:\n",
    "    # delete 'javascript:;' entries & incorrect url entries\n",
    "    del job_links[del_ix[0]]\n",
    "\n",
    "    drop = 1\n",
    "    for i in range(1, len(del_ix)):\n",
    "        del job_links[del_ix[i]-drop]\n",
    "        drop = drop + 1\n",
    "\n",
    "print(\"There are {} jobs to scrape\".format(len(job_links)))\n",
    "\n",
    "# Save job links\n",
    "with open('Job_links_'+category+'.pkl', 'wb') as f:\n",
    "            pickle.dump(job_links, f)\n",
    "\n",
    "\n",
    "# Done cleaning job links\n",
    "\n",
    "print(\"Job_links: \",len(job_links))\n",
    "\n",
    "######################################\n",
    "\n",
    "\n",
    "####### Scraping job attributes ######\n",
    "\n",
    "\n",
    "######################################\n",
    "\n",
    "job_attrs = []\n",
    "not_scraped = 0\n",
    "scraped = 0\n",
    "smile = 0\n",
    "\n",
    "\n",
    "for link in job_links: #start at job 212, bc job 1 is index 0\n",
    "    t = random.randint(8,10)\n",
    "    time.sleep(t)\n",
    "    browser = dc.initialize_driver()\n",
    "    browser.get(link)\n",
    "\n",
    "    try:\n",
    "        # wait for page to load\n",
    "        WebDriverWait(browser, 20).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, 'row'))\n",
    "        )\n",
    "        del_div = browser.find_elements(By.CLASS_NAME, 'row')\n",
    "        # Check if post has been deleted\n",
    "        if del_div[6].text != 'We require users to verify the reCaptcha below to view deleted positions.\\nRelated Searches:\\nBusiness and Financial Services\\nCreate your free job search account\\nReceive new jobs by email\\nPost your resume/CV\\nTrack your applications\\nJoin Now\\nHave an account? Sign in':\n",
    "\n",
    "            job_title = browser.find_element(By.ID, 'jobtitle-header').text\n",
    "            job_loc = browser.find_element(By.CLASS_NAME, 'job-loc').text\n",
    "            div = browser.find_elements(By.ID, 'jobAttrib')\n",
    "            job_attr = div[0].find_element(By.CLASS_NAME, 'job-info').text.split('\\n') # get job data\n",
    "       \n",
    "            div = browser.find_elements(By.ID, 'job')\n",
    "            job_desc = div[0].find_element(By.ID, 'jobDesc').text#.split('\\n')\n",
    "            \n",
    "            job_attr = [job_title] + [job_loc] + job_attr # puts title at the begining of the list\n",
    "            job_attr.append(job_desc) # Append job_description\n",
    "            job_attrs.append(job_attr) # Append job details as list inside another list \n",
    "            \n",
    "            scraped = scraped + 1\n",
    "\n",
    "            browser.quit()\n",
    "            smile = smile +1\n",
    "            if smile == 1:\n",
    "                print('\\nScraping away...\\n')\n",
    "                print('0  0\\n')\n",
    "                print('\\__/\\n')\n",
    "            if smile % 100 == 0:\n",
    "                print(\"{} jobs have been scraped so far...\\n\".format(scraped))\n",
    "                print('0  0\\n')\n",
    "                print('\\__/\\n')\n",
    "            \n",
    "            # Save progress (every job info)\n",
    "            #if smile % 500 == 0: # Every 500 jobs save as pickle\n",
    "                # Store data (serialize)\n",
    "            with open('Job_Attrs_'+category+'.pkl', 'wb') as f:\n",
    "                pickle.dump(job_attrs, f)\n",
    "\n",
    "        elif IndexError:\n",
    "            print('\\nJob {} has been deleted'.format(smile))\n",
    "            not_scraped = not_scraped + 1\n",
    "\n",
    "            browser.quit()\n",
    "            smile = smile +1\n",
    "            if smile == 1:\n",
    "                print('\\nScraping away...\\n')\n",
    "                print('0  0\\n')\n",
    "                print('\\__/\\n')\n",
    "            if smile % 100 == 0:\n",
    "                print(\"{} jobs have been scraped so far...\\n\".format(scraped))\n",
    "                print('0  0\\n')\n",
    "                print('\\__/\\n')\n",
    "            \n",
    "            # Save progress (every job info)\n",
    "            #if smile % 500 == 0: # Every 500 jobs save as pickle\n",
    "                # Store data (serialize)\n",
    "            with open('Job_Attrs_'+category+'.pkl', 'wb') as f:\n",
    "                pickle.dump(job_attrs, f)\n",
    "\n",
    "    except Exception: # If cannot find element\n",
    "\n",
    "        # # wait for page to load\n",
    "        # WebDriverWait(browser, 20).until(\n",
    "        #     EC.presence_of_element_located((By.CLASS_NAME, 'iframe'))\n",
    "        # ) \n",
    "               \n",
    "        # See if exception is related to captcha\n",
    "        if browser.find_elements(By.TAG_NAME,'iframe')[0].text.startswith('Request unsuccessful.'):\n",
    "            \n",
    "            #bypassFullCaptcha()\n",
    "            bypassCaptcha1()\n",
    "            \n",
    "            # Check if we get second captcha check\n",
    "            if browser.find_elements(By.TAG_NAME,'iframe')[0].text.startswith('Request unsuccessful.'):\n",
    "                \n",
    "                bypassCaptcha2()\n",
    "                time.sleep(10)\n",
    "        \n",
    "        try:\n",
    "            print('Looking for job info {}\\n'.format(smile))\n",
    "            print('\\nNot scraped is', not_scraped)\n",
    "            # Successfully moved out of Captcha\n",
    "\n",
    "            # wait for page to load\n",
    "            WebDriverWait(browser, 20).until(\n",
    "                EC.presence_of_element_located((By.CLASS_NAME, 'row'))\n",
    "            )\n",
    "            del_div = browser.find_elements(By.CLASS_NAME, 'row')\n",
    "            # Check if post has been deleted\n",
    "            if del_div[6].text != 'We require users to verify the reCaptcha below to view deleted positions.\\nRelated Searches:\\nBusiness and Financial Services\\nCreate your free job search account\\nReceive new jobs by email\\nPost your resume/CV\\nTrack your applications\\nJoin Now\\nHave an account? Sign in':\n",
    "\n",
    "                job_title = browser.find_element(By.ID, 'jobtitle-header').text\n",
    "                job_loc = browser.find_element(By.CLASS_NAME, 'job-loc').text\n",
    "                div = browser.find_elements(By.ID, 'jobAttrib')\n",
    "                job_attr = div[0].find_element(By.CLASS_NAME, 'job-info').text.split('\\n') # get job data\n",
    "                        #job_attr = [job_title] + job_attr\n",
    "                div = browser.find_elements(By.ID, 'job')\n",
    "                job_desc = div[0].find_element(By.ID, 'jobDesc').text#.split('\\n')\n",
    "                    #job_attr.append(job_desc)\n",
    "                    #job_attrs.append(job_attr)\n",
    "                \n",
    "            #else: # if post is delete\n",
    "                job_attr = [job_title] + [job_loc] + job_attr # puts title at the begining of the list\n",
    "                job_attr.append(job_desc) # Append job_description\n",
    "                job_attrs.append(job_attr) # Append job details as list inside another list \n",
    "                \n",
    "                scraped = scraped + 1\n",
    "                \n",
    "                browser.quit()\n",
    "                smile = smile +1\n",
    "                if smile == 1:\n",
    "                    print('\\nScraping away...\\n')\n",
    "                    print('0  0\\n')\n",
    "                    print('\\__/\\n')\n",
    "                if smile % 100 == 0:\n",
    "                    print(\"{} jobs have been scraped so far...\\n\".format(scraped))\n",
    "                    print('0  0\\n')\n",
    "                    print('\\__/\\n')\n",
    "                \n",
    "                # Save progress (every job info)\n",
    "                #if smile % 500 == 0: # Every 500 jobs save as pickle\n",
    "                    # Store data (serialize)\n",
    "                with open('Job_Attrs_'+category+'.pkl', 'wb') as f:\n",
    "                    pickle.dump(job_attrs, f)\n",
    "\n",
    "            elif IndexError:\n",
    "                print('\\nJob {} has been deleted'.format(smile))\n",
    "                not_scraped = not_scraped + 1\n",
    "\n",
    "                browser.quit()\n",
    "                smile = smile +1\n",
    "                if smile == 1:\n",
    "                    print('\\nScraping away...\\n')\n",
    "                    print('0  0\\n')\n",
    "                    print('\\__/\\n')\n",
    "                if smile % 100 == 0:\n",
    "                    print(\"{} jobs have been scraped so far...\\n\".format(scraped))\n",
    "                    print('0  0\\n')\n",
    "                    print('\\__/\\n')\n",
    "                \n",
    "                # Save progress (every job info)\n",
    "                #if smile % 500 == 0: # Every 500 jobs save as pickle\n",
    "                    # Store data (serialize)\n",
    "                with open('Job_Attrs_'+category+'.pkl', 'wb') as f:\n",
    "                    pickle.dump(job_attrs, f)\n",
    "            \n",
    "        except Exception:\n",
    "\n",
    "            try:\n",
    "                if del_div[6].text.startswith('We require users to verify the reCaptcha below to view deleted positions'):\n",
    "                    \n",
    "                    print('\\nJob {} has been deleted'.format(smile))\n",
    "                    not_scraped = not_scraped + 1\n",
    "\n",
    "                    browser.quit()\n",
    "                    smile = smile +1\n",
    "                    if smile == 1:\n",
    "                        print('\\nScraping away...\\n')\n",
    "                        print('0  0\\n')\n",
    "                        print('\\__/\\n')\n",
    "                    if smile % 100 == 0:\n",
    "                        print(\"{} jobs have been scraped so far...\\n\".format(scraped))\n",
    "                        print('0  0\\n')\n",
    "                        print('\\__/\\n')\n",
    "                    \n",
    "                    # Save progress (every job info)\n",
    "                    #if smile % 500 == 0: # Every 500 jobs save as pickle\n",
    "                        # Store data (serialize)\n",
    "                    with open('Job_Attrs_'+category+'.pkl', 'wb') as f:\n",
    "                        pickle.dump(job_attrs, f)\n",
    "            \n",
    "            except Exception:\n",
    "            # If exception is not b/c job is deleted then we need to pause\n",
    "                # API limit exceeded and need to wait, pause 20 minutes and try again\n",
    "                browser.quit()\n",
    "                print('Pausing 20 minutes, buster API overused!')\n",
    "                time.sleep(1200) # wait 20 minutes :( looooooong\n",
    "\n",
    "                pp = 0\n",
    "                aa = 0\n",
    "                while pp < 1:\n",
    "                    try:\n",
    "                        browser = dc.initialize_driver()\n",
    "                        browser.get(link)\n",
    "\n",
    "                        #browser.switch_to.default_content()\n",
    "                        \n",
    "                        if browser.find_elements(By.TAG_NAME,'iframe')[0].text.startswith('Request unsuccessful.'):\n",
    "                            print('Trying again on job ', smile)\n",
    "\n",
    "                            time.sleep(10)\n",
    "\n",
    "                            bypassCaptcha1()\n",
    "\n",
    "                            bypassCaptcha2()\n",
    "                            time.sleep(10)\n",
    "\n",
    "                            print('Looking for job info {}\\n'.format(smile))\n",
    "                            print('\\nNot scraped is', not_scraped)\n",
    "                                \n",
    "                            # Successfully moved out of Captcha\n",
    "\n",
    "                            # wait for page to load\n",
    "                            WebDriverWait(browser, 20).until(\n",
    "                                EC.presence_of_element_located((By.CLASS_NAME, 'row'))\n",
    "                            )\n",
    "                            del_div = browser.find_elements(By.CLASS_NAME, 'row')\n",
    "                            # Check if post has been deleted\n",
    "                            if del_div[6].text != 'We require users to verify the reCaptcha below to view deleted positions.\\nRelated Searches:\\nBusiness and Financial Services\\nCreate your free job search account\\nReceive new jobs by email\\nPost your resume/CV\\nTrack your applications\\nJoin Now\\nHave an account? Sign in':\n",
    "\n",
    "                                job_title = browser.find_element(By.ID, 'jobtitle-header').text\n",
    "                                job_loc = browser.find_element(By.CLASS_NAME, 'job-loc').text\n",
    "                                div = browser.find_elements(By.ID, 'jobAttrib')\n",
    "                                job_attr = div[0].find_element(By.CLASS_NAME, 'job-info').text.split('\\n') # get job data\n",
    "                                        #job_attr = [job_title] + job_attr\n",
    "                                div = browser.find_elements(By.ID, 'job')\n",
    "                                job_desc = div[0].find_element(By.ID, 'jobDesc').text#.split('\\n')\n",
    "                                    #job_attr.append(job_desc)\n",
    "                                    #job_attrs.append(job_attr)\n",
    "                                \n",
    "                            #else: # if post is delete\n",
    "                                job_attr = [job_title] + [job_loc] + job_attr # puts title at the begining of the list\n",
    "                                job_attr.append(job_desc) # Append job_description\n",
    "                                job_attrs.append(job_attr) # Append job details as list inside another list \n",
    "                                \n",
    "                                scraped = scraped + 1\n",
    "                                \n",
    "                                browser.quit()\n",
    "                                smile = smile +1\n",
    "                                if smile == 1:\n",
    "                                    print('\\nScraping away...\\n')\n",
    "                                    print('0  0\\n')\n",
    "                                    print('\\__/\\n')\n",
    "                                if smile % 100 == 0:\n",
    "                                    print(\"{} jobs have been scraped so far...\\n\".format(scraped))\n",
    "                                    print('0  0\\n')\n",
    "                                    print('\\__/\\n')\n",
    "                                \n",
    "                                # Save progress (every job info)\n",
    "                                #if smile % 500 == 0: # Every 500 jobs save as pickle\n",
    "                                    # Store data (serialize)\n",
    "                                with open('Job_Attrs_'+category+'.pkl', 'wb') as f:\n",
    "                                    pickle.dump(job_attrs, f)\n",
    "                                pp = 1\n",
    "\n",
    "                            elif IndexError:\n",
    "                                print('\\nJob {} has been deleted'.format(smile))\n",
    "                                not_scraped = not_scraped + 1\n",
    "\n",
    "                                browser.quit()\n",
    "                                smile = smile +1\n",
    "                                if smile == 1:\n",
    "                                    print('\\nScraping away...\\n')\n",
    "                                    print('0  0\\n')\n",
    "                                    print('\\__/\\n')\n",
    "                                if smile % 100 == 0:\n",
    "                                    print(\"{} jobs have been scraped so far...\\n\".format(scraped))\n",
    "                                    print('0  0\\n')\n",
    "                                    print('\\__/\\n')\n",
    "                                \n",
    "                                # Save progress (every job info)\n",
    "                                #if smile % 500 == 0: # Every 500 jobs save as pickle\n",
    "                                    # Store data (serialize)\n",
    "                                with open('Job_Attrs_'+category+'.pkl', 'wb') as f:\n",
    "                                    pickle.dump(job_attrs, f)\n",
    "                                pp = 1\n",
    "                            \n",
    "                                \n",
    "                    except Exception:\n",
    "                        time.sleep(60)\n",
    "                        try:\n",
    "                            if del_div[6].text.startswith('We require users to verify the reCaptcha below to view deleted positions'):\n",
    "                    \n",
    "                                print('\\nJob {} has been deleted'.format(smile))\n",
    "                                not_scraped = not_scraped + 1\n",
    "\n",
    "                                browser.quit()\n",
    "                                smile = smile +1\n",
    "                                if smile == 1:\n",
    "                                    print('\\nScraping away...\\n')\n",
    "                                    print('0  0\\n')\n",
    "                                    print('\\__/\\n')\n",
    "                                if smile % 100 == 0:\n",
    "                                    print(\"{} jobs have been scraped so far...\\n\".format(scraped))\n",
    "                                    print('0  0\\n')\n",
    "                                    print('\\__/\\n')\n",
    "                                \n",
    "                                # Save progress (every job info)\n",
    "                                #if smile % 500 == 0: # Every 500 jobs save as pickle\n",
    "                                    # Store data (serialize)\n",
    "                                with open('Job_Attrs_'+category+'.pkl', 'wb') as f:\n",
    "                                    pickle.dump(job_attrs, f)\n",
    "                                pp = 1\n",
    "                        \n",
    "                        except Exception:\n",
    "\n",
    "                            browser.implicitly_wait(7)\n",
    "                            browser.quit()\n",
    "                            pp = 0\n",
    "                            aa = aa + 1\n",
    "                            print('\\naa is \\n', aa)\n",
    "                            if aa == 5: #Let it try a few times\n",
    "                                print('Pausing for 30 minutes')\n",
    "                                time.sleep(1800) \n",
    "                            \n",
    "                            if aa > 5:\n",
    "                                print('Pausing for five hours!')\n",
    "                                time.sleep(18000)\n",
    "                    \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        # else: # if exception not related to captcha, than simply info doesn't exist\n",
    "        #     not_scraped = not_scraped + 1\n",
    "\n",
    "if not_scraped > 0:\n",
    "\n",
    "    if not_scraped == 1:\n",
    "        print('Unfortunately, information for {} job was unable to be scraped.'.format(not_scraped))\n",
    "    \n",
    "    elif not_scraped > 1:\n",
    "        print('Unfortunately, information for {} jobs was unable to be scraped.'.format(not_scraped))\n",
    "\n",
    "print(\"\\nInformation on a total of {} jobs has been scraped\\n\".format(scraped))\n",
    "\n",
    "print(\"\\nLenght of job_attrs is: {}\\n\".format(len(job_attrs)))\n",
    "\n",
    "# Done scrpaing job attributes\n",
    "\n",
    "##################################################"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate all job attrs together and join them in dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "779"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('Job_Attrs_'+category+'.pkl', 'rb') as f:\n",
    "    job_attrs1 = pickle.load(f)\n",
    "\n",
    "len(job_attrs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store in dictionary\n",
    "job_dict = {}\n",
    "for i in range(len(job_attrs)):\n",
    "    job_dict['Job ' + str(i+1)] = job_attrs[i]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scrape",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "10b88bf028bfa9b25f5dbe99d4a0bd4730b6baebc1bad2b22718095ba5dd32bb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
