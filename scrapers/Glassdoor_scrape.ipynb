{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'driver_config' from 'c:\\\\Users\\\\ckelaid\\\\Documents\\\\Scraping\\\\driver_config.py'>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time \n",
    "import random\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import math\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import pickle\n",
    "import GetSalary\n",
    "import importlib\n",
    "import scrape2_2 as scr2\n",
    "import driver_config as dc\n",
    "import numpy as np\n",
    "import scipy.interpolate as si\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "importlib.reload(scr2)\n",
    "importlib.reload(dc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p is:  0\n",
      "p is:  1\n",
      "p is:  2\n",
      "p is:  3\n",
      "p is:  4\n",
      "p is:  5\n",
      "p is:  6\n",
      "p is:  7\n",
      "p is:  8\n",
      "p is:  9\n",
      "p is:  10\n",
      "p is:  11\n",
      "p is:  12\n",
      "p is:  13\n",
      "p is:  14\n",
      "p is:  15\n"
     ]
    }
   ],
   "source": [
    "# Get hrefs\n",
    "# BI Analyst: https://www.glassdoor.com/Job/bi-analyst-jobs-SRCH_KO0,10.htm?clickSource=searchBox\n",
    "# Data Engineer: https://www.glassdoor.com/Job/bi-analyst-jobs-SRCH_KO0,13.htm\n",
    "hrefs = []\n",
    "p = 0\n",
    "browser = dc.initialize_driver()\n",
    "browser.get('https://www.glassdoor.com/Job/bi-analyst-jobs-SRCH_KO0,10.htm?clickSource=searchBox')\n",
    "while p <= 15:\n",
    "    try:\n",
    "        a_tags = browser.find_element(By.ID, 'MainCol').find_elements(By.TAG_NAME, 'a')#[0].get_attribute('href')\n",
    "        for a in a_tags:\n",
    "            hrefs.append(a.get_attribute('href'))\n",
    "        \n",
    "        print(\"p is: \", p)\n",
    "        # Click for next page\n",
    "        page_button = browser.find_element(By.XPATH, \"//button[@class='page  css-1hq9k8 e13qs2071']\")\n",
    "        page_button.click()\n",
    "        page_button.send_keys(Keys.TAB) # move to the next page button\n",
    "        p += 1 # Once p bigger than 3 (so 4 pages) this stops \n",
    "    \n",
    "    except Exception:\n",
    "        browser.implicitly_wait(10)\n",
    "\n",
    "browser.quit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2966"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hrefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "437"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hrefs = list(set(hrefs)) # get unique hrefs only\n",
    "new_hrefs = []\n",
    "for h in hrefs:\n",
    "    if h.startswith('https://www.glassdoor.com/partner/jobListing.htm?'):\n",
    "        new_hrefs.append(h)\n",
    "\n",
    "len(new_hrefs) # 120 => 30 per page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "437"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_hrefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab job info from job_links\n",
    "\n",
    "def get_job_info(keyword:str, hrefs:list) -> list:\n",
    "\n",
    "    jobs = []\n",
    "    # t = random.randint(8,10)\n",
    "    # WebDriverWait(browser, t)\n",
    "    for h in new_hrefs:\n",
    "        browser = dc.initialize_driver()\n",
    "        t = random.randint(8,10)\n",
    "        browser.implicitly_wait(t)\n",
    "        browser.get(h)\n",
    "        try:\n",
    "            # Wait for elements to load\n",
    "            WebDriverWait(browser, 10).until(EC.element_to_be_clickable((By.XPATH, \"//div[@class='css-1rzz8ht ecgq1xb2']\")))\n",
    "            # Click show more first\n",
    "            browser.find_element(By.XPATH, \"//div[@class='css-1rzz8ht ecgq1xb2']\").click()\n",
    "            # job info\n",
    "            job_info = browser.find_element(By.ID, 'JobView').text.split('\\n')\n",
    "            jobs.append(job_info)\n",
    "            browser.quit()\n",
    "            with open(keyword+'.pkl', 'wb') as f:\n",
    "                pickle.dump(jobs, f)\n",
    "        except Exception:\n",
    "            try:\n",
    "                job_info = browser.find_element(By.ID, 'JobView').text.split('\\n')\n",
    "                jobs.append(job_info)\n",
    "                browser.quit()\n",
    "                with open(keyword+'.pkl', 'wb') as f:\n",
    "                    pickle.dump(jobs, f)\n",
    "            except Exception:\n",
    "                print(\"Can't retrieve this job's info\")\n",
    "                browser.quit()\n",
    "    \n",
    "    return jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_csv(keyword:str, job_dict:dict) :\n",
    "\n",
    "    df = pd.DataFrame(job_dict.values(), columns = ['Job Info'], index = job_dict.keys())\n",
    "\n",
    "    df.to_csv(keyword + '_Jobs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape(keyword:str, hrefs:list):\n",
    "\n",
    "    job_infos = get_job_info(keyword, hrefs)\n",
    "\n",
    "    job_dict = {}\n",
    "    for i in range(len(job_infos)):\n",
    "        job_dict['Job ' + str(i+1)] = ' '.join(job_infos[i])\n",
    "    \n",
    "    save_csv(keyword, job_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape('BI_Analyst', new_hrefs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "234"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jobs = []\n",
    "    # t = random.randint(8,10)\n",
    "    # WebDriverWait(browser, t)\n",
    "for h in new_hrefs[234:]:\n",
    "    browser = dc.initialize_driver()\n",
    "    t = random.randint(8,10)\n",
    "    browser.implicitly_wait(t)\n",
    "    browser.get(h)\n",
    "    try:\n",
    "        # Wait for elements to load\n",
    "        WebDriverWait(browser, 10).until(EC.element_to_be_clickable((By.XPATH, \"//div[@class='css-1rzz8ht ecgq1xb2']\")))\n",
    "        # Click show more first\n",
    "        browser.find_element(By.XPATH, \"//div[@class='css-1rzz8ht ecgq1xb2']\").click()\n",
    "        # job info\n",
    "        job_info = browser.find_element(By.ID, 'JobView').text.split('\\n')\n",
    "        jobs.append(job_info)\n",
    "        browser.quit()\n",
    "        with open('Data_Engineer.pkl', 'wb') as f:\n",
    "            pickle.dump(jobs, f)\n",
    "    except Exception:\n",
    "        try:\n",
    "            job_info = browser.find_element(By.ID, 'JobView').text.split('\\n')\n",
    "            jobs.append(job_info)\n",
    "            browser.quit()\n",
    "            with open('BI_Analyst.pkl', 'wb') as f:\n",
    "                pickle.dump(jobs, f)\n",
    "        except Exception:\n",
    "            print(\"Can't retrieve this job's info\")\n",
    "            browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "480"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_dict = {}\n",
    "for i in range(len(jobs)):\n",
    "    job_dict['Job ' + str(i+1)] = ' '.join(jobs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_csv('Data_Engineer', job_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_infos = get_job_info(new_hrefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_dict = {}\n",
    "for i in range(len(job_infos)):\n",
    "    job_dict['Job ' + str(i+1)] = ' '.join(job_infos[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scrape",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "10b88bf028bfa9b25f5dbe99d4a0bd4730b6baebc1bad2b22718095ba5dd32bb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
